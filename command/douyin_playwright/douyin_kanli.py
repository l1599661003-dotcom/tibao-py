import configparser
import json
import os
import time
import random
from datetime import datetime
import sys
from typing import Optional, Dict, Any, List
import traceback

import playwright
import requests
import urllib3

import pandas as pd
import schedule
from loguru import logger
from playwright.sync_api import sync_playwright
from unitl.common import Common

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

"""
    è·å–æŠ–éŸ³åšä¸»çš„æœˆæ€»è¥æ”¶
"""


# é…ç½®å¸¸é‡
def get_base_path():
    """è·å–åŸºç¡€è·¯å¾„ï¼Œæ”¯æŒexeæ‰“åŒ…"""
    try:
        return os.path.dirname(os.path.abspath(sys.argv[0])) if hasattr(sys, '_MEIPASS') else os.path.dirname(
            os.path.abspath(__file__))
    except Exception:
        return os.path.abspath("../..")

def get_resource_path(relative_path):
    """è·å–èµ„æºæ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒexeæ‰“åŒ…"""
    try:
        # PyInstalleråˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹å¹¶å°†è·¯å¾„å­˜å‚¨åœ¨_MEIPASSä¸­
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath("../../WeekAccountUpdate")
    return os.path.join(base_path, relative_path)

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config = configparser.ConfigParser()

    # å°è¯•å¤šä¸ªå¯èƒ½çš„é…ç½®æ–‡ä»¶è·¯å¾„
    config_paths = [
        get_resource_path('WeekAccountUpdate/config.ini'),
        get_resource_path('config.ini'),
        'WeekAccountUpdate/config.ini',
        'config.ini'
    ]

    config_loaded = False
    for config_path in config_paths:
        if os.path.exists(config_path):
            config.read(config_path, encoding='utf-8')
            config_loaded = True
            break

    if not config_loaded:
        logger.error("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶")
        raise FileNotFoundError("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")

    # è§£æé…ç½®
    return {
        'SCHEDULER_CONFIG': {
            'enable_scheduler': config.getboolean('SCHEDULER', 'enable_scheduler'),
            'daily_time': config.get('SCHEDULER', 'daily_time'),
            'run_once': config.getboolean('SCHEDULER', 'run_once'),
            'check_interval': config.getint('SCHEDULER', 'check_interval')
        }
    }

class DouYinSpider:
    def __init__(self):
        self.setup_logger()
        # è®¾ç½®loggerå±æ€§
        self.logger = logger
        # è®¾ç½®cookieå’Œæ•°æ®ç›®å½•ï¼Œæ”¯æŒexeæ‰“åŒ…
        base_path = get_base_path()
        self.cookie_file = os.path.join(base_path, 'cookies.json')
        self.data_dir = os.path.join(base_path, 'data')
        os.makedirs(self.data_dir, exist_ok=True)
        self.base_url = "https://www.xingtu.cn/ad/creator/index"
        self.is_logged_in = False
        self.found_match = False  # æ·»åŠ æ ‡å¿—ä½ä½œä¸ºç±»å±æ€§
        self.api_data = {}  # å­˜å‚¨APIæ•°æ®
        self.common = Common()
        self.current_kol: Optional[Dict[str, str, str]] = None  # å½“å‰æ­£åœ¨å¤„ç†çš„KOLä¿¡æ¯
        self.processed_api_responses = set()  # ç”¨äºè¿½è¸ªå·²å¤„ç†çš„APIå“åº”
        self.marketing_info = {}  # å­˜å‚¨è¥é”€ä¿¡æ¯
        self.last_request_time = 0  # è®°å½•ä¸Šæ¬¡è¯·æ±‚æ—¶é—´
        self.current_video_type = None  # å½“å‰è§†é¢‘ç±»å‹ï¼š'personal' æˆ– 'xingtu'

        # æ–°å¢ï¼šå­˜å‚¨æ‰€æœ‰APIæ•°æ®çš„å­—å…¸ - ç©ºå¯¹è±¡
        self.kol_api_data = {}
        self.other_api_data = {}
        self.yingxiao_api_data = []  # è¥é”€ä¼ æ’­æ•°æ®æ•°ç»„

        # æµè§ˆå™¨ç›¸å…³å±æ€§åˆå§‹åŒ–
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None

    def scrape_user_notes(self, kol_name: str, kol_url: str, star_id: str) -> int:
        """æŠ“å–æŒ‡å®šKOLçš„ç¬”è®°ä¿¡æ¯å¹¶åŒ¹é…æ›´æ–°æ•°æ®åº“
        è¿”å›å€¼ï¼š
        - 1: å¤„ç†æˆåŠŸï¼ˆæ— è®ºæ˜¯å¦æœ‰è¿æ¥ç”¨æˆ·æŒ‰é’®ï¼Œéƒ½ä¼šå°è¯•è·å–æ‰€æœ‰å¯ç”¨çš„æ•°æ®ï¼‰
        - 0: å¤„ç†å¤±è´¥
        """
        try:
            if not self.is_logged_in:
                self.logger.error("æœªç™»å½•çŠ¶æ€ï¼Œæ— æ³•æŠ“å–æ•°æ®")
                return 0

            user_id = star_id  # å®šä¹‰ user_id ä¾›åç»­ä½¿ç”¨
            self.current_kol = {'name': kol_name, 'url': kol_url, 'user_id':star_id}
            self.processed_api_responses.clear()
            # å®Œå…¨é‡ç½®è¥é”€ä¿¡æ¯ï¼Œç¡®ä¿æ•°æ®éš”ç¦»
            self.marketing_info = {'user_id': star_id}
            # é‡ç½®APIæ•°æ®ç¼“å­˜
            self.api_data = {}
            # é‡æ–°åˆå§‹åŒ–KOLæ•°æ®ç»“æ„ - ç©ºå¯¹è±¡ï¼Œåªå¡«å……åŸºæœ¬ä¿¡æ¯
            self.kol_api_data = {}
            self.other_api_data = {}
            self.yingxiao_api_data = []  # é‡ç½®è¥é”€ä¼ æ’­æ•°ç»„
            # æ·»åŠ APIå“åº”å¤„ç†æ ‡å¿—
            self.api_response_processed = False

            # ä¸å†åœ¨å¼€å§‹æ—¶åˆ›å»ºè®°å½•ï¼Œç»Ÿä¸€åœ¨æœ€åä¿å­˜æ‰€æœ‰æ•°æ®
            self.page.goto(kol_url, timeout=30000)
            self.logger.info(f"æˆåŠŸè®¿é—®é¡µé¢: {kol_url}")

            try:
                self.page.wait_for_load_state('networkidle', timeout=5000)
            except Exception as e:
                self.logger.warning(f"ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆæ—¶å‡ºé”™: {str(e)}")

            self.common.random_sleep(3, 4)

            api_data_copy = dict(self.api_data)
            for api_url, response_info in api_data_copy.items():
                if 'data' not in response_info:
                    continue
                response_data = response_info['data']  # æå–å®é™…çš„å“åº”æ•°æ®
                if '/api/author/get_author_base_info' in api_url:
                    self._process_author_base_info(response_data)
                elif '/api/data_sp/check_author_display' in api_url:
                    self._process_author_display(response_data)
                elif '/api/author/get_author_marketing_info' in api_url:
                    self._process_marketing_info(response_data)
                elif '/api/author/get_author_platform_channel_info_v2' in api_url:
                    self._process_author_platform_channel_info_v2(response_data)
                elif '/api/aggregator/get_author_commerce_spread_info' in api_url:
                    self._process_author_commerce_info(response_data)



            # ===== æ–°å¢ï¼šç‚¹å‡»å•†ä¸šèƒ½åŠ›å¹¶å¤„ç†è§†é¢‘ç±»å‹ =====
            try:
                self.logger.info("å¼€å§‹å¤„ç†å•†ä¸šèƒ½åŠ›çš„è§†é¢‘ç±»å‹...")

                # ç‚¹å‡»å•†ä¸šèƒ½åŠ›æ ‡ç­¾
                business_ability_tab = self.page.locator("div.el-tabs__nav >> div:has-text('å•†ä¸šèƒ½åŠ›')")
                if business_ability_tab and business_ability_tab.is_visible():
                    self.api_data = {}
                    time.sleep(0.5)
                    business_ability_tab.click()
                    self.logger.info("æˆåŠŸç‚¹å‡»å•†ä¸šèƒ½åŠ›æ ‡ç­¾")
                    time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½

                    # æŸ¥æ‰¾ä¸¤ä¸ªlabelæ ‡ç­¾
                    try:
                        # æ‰¾åˆ°æ‰€æœ‰el-checkbox-buttonæ ‡ç­¾
                        checkbox_buttons = self.page.locator("label.el-checkbox-button.xt-checkbox-button")
                        button_count = checkbox_buttons.count()

                        # æ‰¾åˆ°ä¸ªäººè§†é¢‘å’Œæ˜Ÿå›¾è§†é¢‘æŒ‰é’®
                        personal_video_btn = None
                        xingtu_video_btn = None

                        for i in range(button_count):
                            btn = checkbox_buttons.nth(i)
                            btn_text = btn.inner_text()

                            if 'ä¸ªäººè§†é¢‘' in btn_text:
                                personal_video_btn = btn
                            elif 'æ˜Ÿå›¾è§†é¢‘' in btn_text:
                                xingtu_video_btn = btn

                        # æ£€æŸ¥æ˜Ÿå›¾è§†é¢‘æ˜¯å¦è¢«ç¦ç”¨
                        xingtu_disabled = False
                        if xingtu_video_btn:
                            xingtu_class = xingtu_video_btn.get_attribute('class')
                            xingtu_disabled = 'is-disabled' in xingtu_class

                        if not xingtu_disabled and xingtu_video_btn:
                            # æ˜Ÿå›¾è§†é¢‘æœªç¦ç”¨ï¼Œé»˜è®¤é€‰ä¸­çš„æ˜¯æ˜Ÿå›¾è§†é¢‘
                            self.logger.info("æ˜Ÿå›¾è§†é¢‘æœªç¦ç”¨ï¼Œè·å–æ˜Ÿå›¾è§†é¢‘æ•°æ® (business=1)...")

                            # ç¡®ä¿æ˜Ÿå›¾è§†é¢‘è¢«é€‰ä¸­
                            xingtu_class = xingtu_video_btn.get_attribute('class')
                            if 'is-checked' not in xingtu_class:
                                xingtu_video_btn.click()
                                self.logger.info("ç‚¹å‡»æ˜Ÿå›¾è§†é¢‘æŒ‰é’®")
                                time.sleep(2)

                            # ç­‰å¾…å¹¶æ ‡è®°ä¸ºè·å–æ˜Ÿå›¾è§†é¢‘æ•°æ®
                            self.current_video_type = 'xingtu'  # æ ‡è®°å½“å‰è§†é¢‘ç±»å‹

                            # ã€å…³é”®ä¿®å¤ã€‘ä¸»åŠ¨ç­‰å¾…æ˜Ÿå›¾è§†é¢‘ spread_info API å‡ºç°
                            self.logger.info("ç­‰å¾…æ˜Ÿå›¾è§†é¢‘APIæ•°æ®åŠ è½½...")
                            max_wait_time = 15  # æœ€å¤šç­‰å¾…15ç§’
                            poll_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
                            waited_time = 0
                            api_found = False

                            self.logger.info(f"å¼€å§‹è½®è¯¢ç­‰å¾…æ˜Ÿå›¾è§†é¢‘ spread_info API (æœ€å¤šç­‰å¾…{max_wait_time}ç§’)...")

                            while waited_time < max_wait_time:
                                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ˜Ÿå›¾è§†é¢‘çš„ spread_info API
                                xingtu_spread_count = sum(
                                    1 for url in self.api_data.keys()
                                    if '/api/data_sp/get_author_spread_info' in url
                                    and ('type=2' in url or 'only_assign=true' in url)
                                )

                                if xingtu_spread_count > 0:
                                    self.logger.info(f"âœ… æ£€æµ‹åˆ°æ˜Ÿå›¾è§†é¢‘ spread_info APIï¼ç­‰å¾…æ—¶é—´: {waited_time:.1f}ç§’")
                                    api_found = True
                                    break

                                # ã€å…³é”®ã€‘ä½¿ç”¨ page.wait_for_timeout è€Œä¸æ˜¯ time.sleep
                                # è¿™æ ·å¯ä»¥è®© playwright äº‹ä»¶å¾ªç¯å¤„ç†å“åº”
                                self.page.wait_for_timeout(int(poll_interval * 1000))
                                waited_time += poll_interval

                            if not api_found:
                                self.logger.warning(f"â° ç­‰å¾…è¶…æ—¶({max_wait_time}ç§’)ï¼Œæœªæ£€æµ‹åˆ°æ˜Ÿå›¾è§†é¢‘ spread_info API")

                            # å¤„ç†å•†ä¸šèƒ½åŠ›é¡µé¢çš„æ‰€æœ‰APIæ•°æ®
                            self.logger.info("å¤„ç†å•†ä¸šèƒ½åŠ›é¡µé¢çš„APIæ•°æ®...")

                            # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰æ•è·åˆ°çš„API
                            self.logger.info(f"ğŸ“Š å½“å‰ api_data ä¸­æœ‰ {len(self.api_data)} ä¸ªAPI")
                            for api_url in self.api_data.keys():
                                self.logger.info(f"  - {api_url}")

                            # 1. å¤„ç†æ˜Ÿå›¾è§†é¢‘çš„ spread_info (type=2, only_assign=true)
                            xingtu_spread_apis = []
                            for api_url, response_info in self.api_data.items():
                                if 'data' not in response_info:
                                    continue
                                # åˆ¤æ–­æ¡ä»¶æ”¹ä¸ºï¼šåŒ…å« type=2 æˆ– only_assign=true
                                if '/api/data_sp/get_author_spread_info' in api_url and ('type=2' in api_url or 'only_assign=true' in api_url):
                                    xingtu_spread_apis.append((api_url, response_info))

                            self.logger.info(f"æ‰¾åˆ° {len(xingtu_spread_apis)} ä¸ªæ˜Ÿå›¾ spread_info API")
                            if xingtu_spread_apis:
                                _, last_response_info = xingtu_spread_apis[-1]
                                response_data = last_response_info['data']
                                self.logger.info(f"ä½¿ç”¨æœ€åä¸€ä¸ªæ˜Ÿå›¾ spread_info API")
                                self._process_author_spread_info(response_data, user_id)
                            else:
                                self.logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ˜Ÿå›¾ spread_info API (type=2)")

                            # 2. å¤„ç†ç§è‰ä»·å€¼ (commerce_seed_base_info)
                            for api_url, response_info in self.api_data.items():
                                if 'data' not in response_info:
                                    continue
                                if '/api/aggregator/get_author_commerce_seed_base_info' in api_url:
                                    response_data = response_info['data']
                                    self.logger.info("å¤„ç†ç§è‰ä»·å€¼æ•°æ®...")
                                    self._process_author_commerce_seed_base_info(response_data, user_id)
                                    break

                            # 3. å¤„ç†è½¬åŒ–ä»·å€¼ (convert_ability)
                            for api_url, response_info in self.api_data.items():
                                if 'data' not in response_info:
                                    continue
                                if '/api/data_sp/get_author_convert_ability' in api_url:
                                    response_data = response_info['data']
                                    self.logger.info("å¤„ç†è½¬åŒ–ä»·å€¼æ•°æ®...")
                                    self._process_author_convert_ability(response_data, user_id)
                                    break

                            # å¤„ç†å®Œæ˜Ÿå›¾æ•°æ®åï¼Œå…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ä¸ªäººè§†é¢‘çš„APIï¼ˆå¯èƒ½ä¸€èµ·åŠ è½½äº†ï¼‰
                            self.logger.info("æ£€æŸ¥æ˜¯å¦å·²ç»æ•è·åˆ°ä¸ªäººè§†é¢‘çš„ spread_info API...")

                            # æŸ¥æ‰¾ä¸ªäººè§†é¢‘çš„ spread_info (type=1 æˆ– only_assign=false)
                            personal_spread_in_current = []
                            for api_url, response_info in self.api_data.items():
                                if 'data' not in response_info:
                                    continue
                                if '/api/data_sp/get_author_spread_info' in api_url and ('type=1' in api_url or 'only_assign=false' in api_url):
                                    personal_spread_in_current.append((api_url, response_info))

                            if personal_spread_in_current:
                                # å¦‚æœå·²ç»æœ‰ä¸ªäººè§†é¢‘æ•°æ®ï¼Œç›´æ¥å¤„ç†ï¼Œä¸éœ€è¦ç‚¹å‡»
                                self.logger.info(f"âœ… å·²ç»æ•è·åˆ° {len(personal_spread_in_current)} ä¸ªä¸ªäºº spread_info APIï¼Œæ— éœ€ç‚¹å‡»")
                                self.current_video_type = 'personal'
                                _, last_response_info = personal_spread_in_current[-1]
                                response_data = last_response_info['data']
                                self.logger.info(f"ä½¿ç”¨å·²æ•è·çš„ä¸ªäºº spread_info API")
                                self._process_author_spread_info(response_data, user_id)
                                self.logger.info("âœ… å·²è·å–ä¸ªäººè§†é¢‘æ•°æ® (type=1)")
                            elif personal_video_btn:
                                # æ²¡æœ‰ä¸ªäººè§†é¢‘æ•°æ®ï¼Œéœ€è¦ç‚¹å‡»åˆ‡æ¢
                                self.logger.info("æœªæ‰¾åˆ°ä¸ªäººè§†é¢‘APIï¼Œå‡†å¤‡ç‚¹å‡»ä¸ªäººè§†é¢‘æŒ‰é’®")

                                # ã€é‡è¦ã€‘å…ˆè®¾ç½®è§†é¢‘ç±»å‹ï¼Œå†æ¸…ç©ºï¼Œå†ç‚¹å‡»
                                # è¿™æ · handler å¯ä»¥æ­£ç¡®è¯†åˆ«æ–°çš„API
                                self.current_video_type = 'personal'
                                self.logger.info("å·²è®¾ç½® current_video_type = 'personal'")

                                # æ¸…ç©ºåå†ç‚¹å‡»ä¸ªäººè§†é¢‘
                                self.api_data = {}
                                self.logger.info("å·²æ¸…ç©º api_data")

                                self.logger.info("ç‚¹å‡»ä¸ªäººè§†é¢‘æŒ‰é’®...")
                                personal_video_btn.click()

                                # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                                try:
                                    self.page.wait_for_load_state('networkidle', timeout=5000)
                                    self.logger.info("é¡µé¢ç½‘ç»œç©ºé—²")
                                except Exception as e:
                                    self.logger.warning(f"ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆæ—¶å‡ºé”™: {str(e)}")

                                self.logger.info("ç­‰å¾…ä¸ªäººè§†é¢‘APIæ•°æ®åŠ è½½...")

                                # ã€å…³é”®ä¿®å¤ã€‘ä¸»åŠ¨ç­‰å¾… spread_info API å‡ºç°ï¼Œè€Œä¸æ˜¯ç›²ç›®ç­‰å¾…å›ºå®šæ—¶é—´
                                max_wait_time = 15  # æœ€å¤šç­‰å¾…15ç§’
                                poll_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
                                waited_time = 0
                                api_found = False

                                while waited_time < max_wait_time:
                                    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ä¸ªäººè§†é¢‘çš„ spread_info API
                                    personal_spread_count = sum(
                                        1 for url in self.api_data.keys()
                                        if '/api/data_sp/get_author_spread_info' in url
                                        and ('type=1' in url or 'only_assign=false' in url)
                                    )

                                    if personal_spread_count > 0:
                                        api_found = True
                                        break

                                    # ã€å…³é”®ã€‘ä½¿ç”¨ page.wait_for_timeout è€Œä¸æ˜¯ time.sleep
                                    # è¿™æ ·å¯ä»¥è®© playwright äº‹ä»¶å¾ªç¯å¤„ç†å“åº”
                                    self.page.wait_for_timeout(int(poll_interval * 1000))
                                    waited_time += poll_interval

                                if not api_found:
                                    self.logger.warning(f"â° ç­‰å¾…è¶…æ—¶({max_wait_time}ç§’)ï¼Œæœªæ£€æµ‹åˆ°ä¸ªäººè§†é¢‘ spread_info API")

                                # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰æ•è·åˆ°çš„API
                                for api_url in self.api_data.keys():
                                    self.logger.info(f"  - {api_url}")

                                # å¤„ç†ä¸ªäººè§†é¢‘çš„ spread_info (type=1, only_assign=false)
                                personal_spread_apis = []
                                for api_url, response_info in self.api_data.items():
                                    if 'data' not in response_info:
                                        continue
                                    # åˆ¤æ–­æ¡ä»¶æ”¹ä¸ºï¼šåŒ…å« type=1 æˆ– only_assign=false
                                    if '/api/data_sp/get_author_spread_info' in api_url and ('type=1' in api_url or 'only_assign=false' in api_url):
                                        personal_spread_apis.append((api_url, response_info))

                                self.logger.info(f"æ‰¾åˆ° {len(personal_spread_apis)} ä¸ªä¸ªäºº spread_info API")
                                if personal_spread_apis:
                                    _, last_response_info = personal_spread_apis[-1]
                                    response_data = last_response_info['data']
                                    self.logger.info(f"ä½¿ç”¨æœ€åä¸€ä¸ªä¸ªäºº spread_info API")
                                    self._process_author_spread_info(response_data, user_id)
                                else:
                                    self.logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä¸ªäºº spread_info API (type=1)")

                                self.logger.info("âœ… å·²è·å–ä¸ªäººè§†é¢‘æ•°æ® (type=1)")
                        else:
                            # æ˜Ÿå›¾è§†é¢‘è¢«ç¦ç”¨ï¼Œé»˜è®¤æ˜¯ä¸ªäººè§†é¢‘
                            self.logger.info("æ˜Ÿå›¾è§†é¢‘å·²ç¦ç”¨ï¼Œåªè·å–ä¸ªäººè§†é¢‘æ•°æ® (type=1)...")

                            # ç¡®ä¿ä¸ªäººè§†é¢‘è¢«é€‰ä¸­
                            if personal_video_btn:
                                personal_class = personal_video_btn.get_attribute('class')
                                if 'is-checked' not in personal_class:
                                    personal_video_btn.click()
                                    self.logger.info("ç‚¹å‡»ä¸ªäººè§†é¢‘æŒ‰é’®")
                                    time.sleep(2)

                            # æ ‡è®°ä¸ºè·å–ä¸ªäººè§†é¢‘æ•°æ®
                            self.current_video_type = 'personal'

                            # ã€å…³é”®ä¿®å¤ã€‘ä¸»åŠ¨ç­‰å¾…ä¸ªäººè§†é¢‘ spread_info API å‡ºç°
                            self.logger.info("ç­‰å¾…ä¸ªäººè§†é¢‘APIæ•°æ®åŠ è½½...")
                            max_wait_time = 15  # æœ€å¤šç­‰å¾…15ç§’
                            poll_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
                            waited_time = 0
                            api_found = False

                            self.logger.info(f"å¼€å§‹è½®è¯¢ç­‰å¾…ä¸ªäººè§†é¢‘ spread_info API (æœ€å¤šç­‰å¾…{max_wait_time}ç§’)...")

                            while waited_time < max_wait_time:
                                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ä¸ªäººè§†é¢‘çš„ spread_info API
                                personal_spread_count = sum(
                                    1 for url in self.api_data.keys()
                                    if '/api/data_sp/get_author_spread_info' in url
                                    and ('type=1' in url or 'only_assign=false' in url)
                                )

                                if personal_spread_count > 0:
                                    self.logger.info(f"âœ… æ£€æµ‹åˆ°ä¸ªäººè§†é¢‘ spread_info APIï¼ç­‰å¾…æ—¶é—´: {waited_time:.1f}ç§’")
                                    api_found = True
                                    break

                                # ã€å…³é”®ã€‘ä½¿ç”¨ page.wait_for_timeout è€Œä¸æ˜¯ time.sleep
                                # è¿™æ ·å¯ä»¥è®© playwright äº‹ä»¶å¾ªç¯å¤„ç†å“åº”
                                self.page.wait_for_timeout(int(poll_interval * 1000))
                                waited_time += poll_interval

                            if not api_found:
                                self.logger.warning(f"â° ç­‰å¾…è¶…æ—¶({max_wait_time}ç§’)ï¼Œæœªæ£€æµ‹åˆ°ä¸ªäººè§†é¢‘ spread_info API")

                            # å¤„ç†ä¸ªäººè§†é¢‘çš„ spread_info (type=1 æˆ– only_assign=false)
                            personal_spread_apis = []
                            for api_url, response_info in self.api_data.items():
                                if 'data' not in response_info:
                                    continue
                                if '/api/data_sp/get_author_spread_info' in api_url and ('type=1' in api_url or 'only_assign=false' in api_url):
                                    personal_spread_apis.append((api_url, response_info))

                            if personal_spread_apis:
                                # ä½¿ç”¨æœ€åä¸€ä¸ª API å“åº”ï¼ˆç¬¬ä¸€ä¸ªå¯èƒ½æ²¡æœ‰æ•°æ®ï¼‰
                                _, last_response_info = personal_spread_apis[-1]
                                response_data = last_response_info['data']
                                self.logger.info(f"æ‰¾åˆ° {len(personal_spread_apis)} ä¸ªä¸ªäºº spread_info APIï¼Œä½¿ç”¨æœ€åä¸€ä¸ª")
                                self._process_author_spread_info(response_data, user_id)

                    except Exception as btn_error:
                        self.logger.warning(f"å¤„ç†è§†é¢‘ç±»å‹æŒ‰é’®æ—¶å‡ºé”™: {str(btn_error)}")

                else:
                    # æœªæ‰¾åˆ°å•†ä¸šèƒ½åŠ›æ ‡ç­¾ï¼Œä½¿ç”¨é¦–é¡µé»˜è®¤æ•°æ®
                    self.logger.info("æœªæ‰¾åˆ°å•†ä¸šèƒ½åŠ›æ ‡ç­¾ï¼Œä½¿ç”¨é¦–é¡µé»˜è®¤çš„ä¼ æ’­ä¿¡æ¯æ•°æ®")

                    # é¦–é¡µé»˜è®¤æ˜¯ä¸ªäººè§†é¢‘æ•°æ®
                    self.current_video_type = 'personal'

                    # å¤„ç†é¦–é¡µçš„ spread_info - é€‰æ‹©æœ€åä¸€ä¸ªï¼ˆç¬¬ä¸€ä¸ªå¯èƒ½æ²¡æœ‰æ•°æ®ï¼‰
                    homepage_spread_apis = []
                    for api_url, response_info in api_data_copy.items():
                        if 'data' not in response_info:
                            continue
                        if '/api/data_sp/get_author_spread_info' in api_url:
                            homepage_spread_apis.append((api_url, response_info))

                    if homepage_spread_apis:
                        # ä½¿ç”¨æœ€åä¸€ä¸ª API å“åº”ï¼ˆé¦–é¡µåŠ è½½æ—¶ç¬¬ä¸€ä¸ªå¯èƒ½æ²¡æœ‰æ•°æ®ï¼‰
                        _, last_response_info = homepage_spread_apis[-1]
                        response_data = last_response_info['data']
                        self.logger.info(f"é¦–é¡µæ‰¾åˆ° {len(homepage_spread_apis)} ä¸ª spread_info APIï¼Œä½¿ç”¨æœ€åä¸€ä¸ª")
                        self._process_author_spread_info(response_data, user_id)

            except Exception as ability_error:
                self.logger.warning(f"å¤„ç†å•†ä¸šèƒ½åŠ›æ—¶å‡ºé”™: {str(ability_error)}")

            # ===== å•†ä¸šèƒ½åŠ›å¤„ç†ç»“æŸ =====

            # ç‚¹å‡»è¿æ¥ç”¨æˆ·æ ‡ç­¾
            creative_tab = self.page.locator("div.el-tabs__nav >> div:has-text('è¿æ¥ç”¨æˆ·')")
            if creative_tab and creative_tab.is_visible():
                # ç‚¹å‡»å‰ç­‰å¾…ä¸€ä¸‹ç¡®ä¿å…ƒç´ ç¨³å®š
                time.sleep(0.5)
                creative_tab.click()
                self.logger.info("æˆåŠŸç‚¹å‡»è¿æ¥ç”¨æˆ·æ ‡ç­¾")

                try:
                    self.page.wait_for_load_state('networkidle', timeout=5000)
                except Exception as e:
                    self.logger.warning(f"ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆæ—¶å‡ºé”™: {str(e)}")

                # é¼ æ ‡æ»šè½®å‘ä¸‹æ»šåŠ¨å‡ ä¸‹ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
                self.logger.info("å‘ä¸‹æ»šåŠ¨é¡µé¢ç¡®ä¿å†…å®¹å®Œå…¨åŠ è½½...")
                try:
                    # å‘ä¸‹æ»šåŠ¨3æ¬¡ï¼Œæ¯æ¬¡æ»šåŠ¨500åƒç´ 
                    for i in range(3):
                        self.page.mouse.wheel(0, 500)
                        time.sleep(0.5)  # æ¯æ¬¡æ»šåŠ¨åç­‰å¾…0.5ç§’
                    self.logger.info("é¡µé¢æ»šåŠ¨å®Œæˆ")
                except Exception as e:
                    self.logger.warning(f"é¡µé¢æ»šåŠ¨æ—¶å‡ºé”™: {str(e)}")

                # å°è¯•ç‚¹å‡»ç²‰ä¸ç”»åƒæŒ‰é’®
                self.logger.info("å¼€å§‹ç‚¹å‡»ç²‰ä¸ç”»åƒæŒ‰é’®...")

                # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½ï¼Œç¡®ä¿æ‰€æœ‰å…ƒç´ éƒ½å·²æ¸²æŸ“
                self.logger.info("ç­‰å¾…é¡µé¢å…ƒç´ å®Œå…¨åŠ è½½...")
                try:
                    self.page.wait_for_load_state('networkidle', timeout=5000)
                except Exception as e:
                    self.logger.warning(f"ç­‰å¾…é¡µé¢ç½‘ç»œç©ºé—²æ—¶å‡ºé”™: {str(e)}")

                fan_portrait_button = self.page.locator("text=ç²‰ä¸ç”»åƒ")
                if fan_portrait_button and fan_portrait_button.is_visible():
                    # ã€é‡è¦ã€‘ç‚¹å‡»å‰æ¸…ç©º api_dataï¼Œç¡®ä¿åªæ•è·ç²‰ä¸ç”»åƒç›¸å…³çš„API
                    self.api_data = {}
                    self.logger.info("å·²æ¸…ç©º api_dataï¼Œå‡†å¤‡ç‚¹å‡»ç²‰ä¸ç”»åƒæŒ‰é’®")

                    time.sleep(0.5)
                    fan_portrait_button.click()
                    self.logger.info("æˆåŠŸç‚¹å‡»ç²‰ä¸ç”»åƒæŒ‰é’®")

                    # ã€å…³é”®ã€‘ä¸»åŠ¨ç­‰å¾…ç²‰ä¸åˆ†å¸ƒAPIå‡ºç°
                    max_wait_time = 15  # æœ€å¤šç­‰å¾…15ç§’
                    poll_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
                    waited_time = 0
                    api_found = False

                    self.logger.info(f"å¼€å§‹è½®è¯¢ç­‰å¾…ç²‰ä¸åˆ†å¸ƒ API (æœ€å¤šç­‰å¾…{max_wait_time}ç§’)...")

                    while waited_time < max_wait_time:
                        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç²‰ä¸åˆ†å¸ƒçš„ API
                        fans_api_count = sum(
                            1 for url in self.api_data.keys()
                            if '/api/data_sp/get_author_fans_distribution' in url
                        )

                        if fans_api_count > 0:
                            self.logger.info(f"âœ… æ£€æµ‹åˆ°ç²‰ä¸åˆ†å¸ƒ APIï¼ç­‰å¾…æ—¶é—´: {waited_time:.1f}ç§’")
                            api_found = True
                            break

                        # ã€å…³é”®ã€‘ä½¿ç”¨ page.wait_for_timeout è€Œä¸æ˜¯ time.sleep
                        # è¿™æ ·å¯ä»¥è®© playwright äº‹ä»¶å¾ªç¯å¤„ç†å“åº”
                        self.page.wait_for_timeout(int(poll_interval * 1000))
                        waited_time += poll_interval

                    if not api_found:
                        self.logger.warning(f"â° ç­‰å¾…è¶…æ—¶({max_wait_time}ç§’)ï¼Œæœªæ£€æµ‹åˆ°ç²‰ä¸åˆ†å¸ƒ API")

                    # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰æ•è·åˆ°çš„API
                    self.logger.info(f"ğŸ“Š ç‚¹å‡»ç²‰ä¸ç”»åƒåï¼Œapi_data ä¸­æœ‰ {len(self.api_data)} ä¸ªAPI")
                    for api_url in self.api_data.keys():
                        self.logger.info(f"  - {api_url}")

                    self.logger.info("å¤„ç†è¿æ¥ç”¨æˆ·é¡µé¢çš„APIæ•°æ®...")

                    # 1. å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒ (link_card)
                    for api_url, response_info in self.api_data.items():
                        if 'data' not in response_info:
                            continue
                        if '/api/data_sp/author_link_card' in api_url:
                            response_data = response_info['data']
                            self.logger.info("å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒæ•°æ®...")
                            self._process_author_link_card(response_data, user_id)
                            break

                    # 2. å¤„ç†ç²‰ä¸æ•°æ® (fans_distribution)
                    self.logger.info(f"å¼€å§‹æŸ¥æ‰¾ç²‰ä¸åˆ†å¸ƒAPIï¼Œå½“å‰api_dataæœ‰ {len(self.api_data)} ä¸ªAPI")
                    fans_api_found = False
                    for api_url, response_info in self.api_data.items():
                        if 'data' not in response_info:
                            continue
                        if '/api/data_sp/get_author_fans_distribution' in api_url:
                            fans_api_found = True
                            response_data = response_info['data']
                            self.logger.info(f"âœ… æ‰¾åˆ°ç²‰ä¸åˆ†å¸ƒAPI: {api_url}")
                            self.logger.info("å¤„ç†ç²‰ä¸æ•°æ®åˆ†å¸ƒ...")
                            self._process_author_fans_distribution(response_data, user_id)
                            break

                    if not fans_api_found:
                        self.logger.warning("âš ï¸ æœªæ‰¾åˆ°ç²‰ä¸åˆ†å¸ƒAPIæ•°æ®")
                else:
                    self.logger.warning("æœªæ‰¾åˆ°ç²‰ä¸ç”»åƒæŒ‰é’®ï¼Œè·³è¿‡ç²‰ä¸æ•°æ®è·å–")

            # ç»Ÿä¸€ä¿å­˜æ‰€æœ‰æ”¶é›†åˆ°çš„APIæ•°æ®åˆ°è¿œç¨‹æ¥å£
            if self.current_kol and self.current_kol.get('user_id'):
                self.logger.info("å¼€å§‹ç»Ÿä¸€ä¿å­˜æ‰€æœ‰APIæ•°æ®åˆ°è¿œç¨‹æ¥å£")
                self._save_all_kol_data_to_api(self.current_kol.get('user_id'))
                self.logger.info("âœ… æ‰€æœ‰APIæ•°æ®å·²ç»Ÿä¸€ä¿å­˜åˆ°è¿œç¨‹æ¥å£")

            return 1  # è¿”å›1è¡¨ç¤ºå¤„ç†æˆåŠŸ

        except Exception as e:
            self.logger.error(f"æŠ“å–KOL {kol_name} ç¬”è®°æ—¶å‡ºé”™: {str(e)}")
            raise



    def _save_all_kol_data_to_api(self, user_id: str):
        """ç»Ÿä¸€ä¿å­˜æ‰€æœ‰æ”¶é›†åˆ°çš„APIæ•°æ®åˆ°è¿œç¨‹æ¥å£"""
        try:
            self.logger.info(f"å¼€å§‹ç»Ÿä¸€ä¿å­˜æ‰€æœ‰APIæ•°æ®åˆ°è¿œç¨‹æ¥å£ï¼Œç”¨æˆ·ID: {user_id}")
            print("=" * 60)
            print("kol_api_data:")
            print(self.kol_api_data)
            print("=" * 60)
            print("other_api_data:")
            print(self.other_api_data)
            print("=" * 60)
            print("yingxiao_api_data:")
            print(self.yingxiao_api_data)
            print("=" * 60)

            # æ„å»ºpayloadï¼Œå‚è€ƒget_pgy_intro.pyçš„æ ¼å¼
            payload = {
                "apis": [
                    {"tb_name": "blogger_info", "tb_data": [self.kol_api_data]},
                    {"tb_name": "blogger_note_rate", "tb_data": []},
                    {"tb_name": "blogger_data_summary", "tb_data": []},
                    {"tb_name": "blogger_note_detail", "tb_data": []},
                    {"tb_name": "blogger_fans_summary", "tb_data": []},
                    {"tb_name": "blogger_fans_profile", "tb_data": []},
                    {"tb_name": "blogger_fans_history", "tb_data": []},
                    {"tb_name": "douyin_kol_profile", "tb_data": [self.other_api_data]},
                    {"tb_name": "douyin_kol_marketing_stats", "tb_data": [self.yingxiao_api_data]},
                ],
                "client_id": 1
            }

            self.logger.info(f"å‡†å¤‡å‘é€æ•°æ®åˆ°APIæ¥å£")

            # å‘é€POSTè¯·æ±‚åˆ°APIæ¥å£
            api_url = "http://47.104.76.46:19000/api/v1/sync/spider/data"
            headers = {
                "Content-Type": "application/json"
            }

            response = requests.post(api_url, json=payload, headers=headers, timeout=30, verify=False)

            if response.status_code == 200:
                try:
                    response_data = response.json()
                    if response_data.get('code') == 200:
                        self.logger.info(f"âœ… æ•°æ®æˆåŠŸå‘é€åˆ°APIæ¥å£ï¼Œå“åº”: {response_data}")
                    else:
                        self.logger.error(f"âŒ APIæ¥å£è¯·æ±‚å¤±è´¥ï¼ŒAPIè¿”å›é”™è¯¯: {response_data}")
                        raise Exception(f"APIæ¥å£è¯·æ±‚å¤±è´¥: {response_data}")
                except ValueError:
                    self.logger.error(f"APIè¿”å›éJSONå“åº”: {response.text[:200]}")
                    raise Exception(f"APIè¿”å›éJSONå“åº”")
            else:
                self.logger.error(f"âŒ APIæ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                self.logger.error(f"å“åº”å†…å®¹: {response.text}")
                raise Exception(f"APIæ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")

        except Exception as api_error:
            self.logger.error(f"ç»Ÿä¸€ä¿å­˜APIæ•°æ®åˆ°è¿œç¨‹æ¥å£æ—¶å‡ºé”™: {str(api_error)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise

    def _process_marketing_info(self, response_data: Dict[str, Any]):
        """å¤„ç†è¥é”€ä¿¡æ¯æ•°æ® - æ ¹æ®æ–°è¡¨ç»“æ„è°ƒæ•´å­—æ®µå"""
        try:
            if not response_data:
                self.logger.error("è¥é”€ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # æŠ¥ä»·ä¿¡æ¯
            if 'price_info' in response_data:
                price_list = response_data['price_info']
                for price in price_list:
                    video_type = price.get('video_type')
                    price_value = price.get('price', 0)
                    if video_type == 1:
                        self.other_api_data['price_1_20s'] = price_value  # 1-20ç§’æŠ¥ä»·
                    elif video_type == 2:
                        self.other_api_data['price_20_60s'] = price_value  # 20-60ç§’æŠ¥ä»·
                        self.kol_api_data['picturePrice'] = price_value
                        self.kol_api_data['videoPrice'] = price_value
                    elif video_type == 71:
                        self.other_api_data['price_60s_plus'] = price_value  # 60ç§’ä»¥ä¸ŠæŠ¥ä»·
                    elif video_type == 150:
                        self.other_api_data['price_platform_raw'] = price_value  # çŸ­ç›´ç§è‰å¹³å°è£¸ä»·

        except Exception as e:
            self.logger.error(f"å¤„ç†è¥é”€ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_base_info(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…åŸºæœ¬ä¿¡æ¯æ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬226-247è¡Œ"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…åŸºæœ¬ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # æ€§åˆ«è½¬æ¢
            gender = response_data.get('gender', '')
            if gender == 1:
                gender = 2
            elif gender == 2:
                gender = 1
            # 1. åŸºæœ¬ä¿¡æ¯
            self.kol_api_data['name'] = response_data.get('nick_name', '')
            self.kol_api_data['platform_user_id'] = response_data.get('id')
            self.kol_api_data['location'] = response_data.get('city')
            self.kol_api_data['gender'] = gender
            tags_relation = response_data.get('tags_relation', {})
            if tags_relation:
                content_field = []
                for k, v in tags_relation.items():
                    content_field.append({
                        "taxonomy1Tag": k,  # ä¸€çº§æ ‡ç­¾
                        "taxonomy2Tags": v or []  # äºŒçº§æ ‡ç­¾æ•°ç»„
                    })
                self.kol_api_data['contentTags'] = content_field
            else:
                self.kol_api_data['contentTags'] = []

            self.other_api_data['douyin_sec_uid'] = response_data.get('sec_uid', '')
            self.other_api_data['platform_user_id'] = response_data.get('id')

        except Exception as e:
            self.logger.error(f"å¤„ç†ä½œè€…åŸºæœ¬ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_display(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…æ˜¾ç¤ºæ£€æŸ¥APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬249-253è¡Œ"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…æ˜¾ç¤ºæ£€æŸ¥APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 2. ç²‰ä¸æ•°èµè—
            self.kol_api_data['fansNum'] = response_data.get('follower', 0)
            self.kol_api_data['likeCollectCountInfo'] = response_data.get('link_cnt', 0)

        except Exception as e:
            self.logger.error(f"å¤„ç†ä½œè€…æ˜¾ç¤ºæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_platform_channel_info_v2(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…é“¾æ¥ç»“æ„APIæ•°æ®ï¼Œä¿å­˜link_structå¯¹è±¡ä¸ºJSONæ ¼å¼"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…é“¾æ¥ç»“æ„APIå“åº”æ•°æ®ä¸ºç©º")
                return

            self.kol_api_data['creator_intro'] = response_data.get('self_intro', {})

        except Exception as e:
            self.logger.error(f"å¤„ç†é“¾æ¥ç»“æ„æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_commerce_info(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…å•†ä¸šä¼ æ’­ä¿¡æ¯APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬349-359è¡Œ"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…å•†ä¸šä¼ æ’­ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 6. é¢„ä¼°CPE/CPM
            self.other_api_data['expect_cpe'] = response_data.get('cpe_20_60', '')
            self.other_api_data['expect_cpm'] = response_data.get('cpm_20_60', '')
            self.other_api_data['platform_hot_rate'] = response_data.get('platform_hot_rate', '')
            self.other_api_data['expect_read'] = response_data.get('vv', '')

        except Exception as e:
            self.logger.error(f"å¤„ç†å•†ä¸šä¼ æ’­ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_spread_info(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…ä¼ æ’­ä¿¡æ¯APIæ•°æ® - å­˜å…¥yingxiao_api_dataæ•°ç»„"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†ä¼ æ’­ä¿¡æ¯APIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}ï¼Œè§†é¢‘ç±»å‹: {self.current_video_type}")

            if not response_data:
                self.logger.error("ä½œè€…ä¼ æ’­ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # æå–åŸºç¡€æ•°æ®
            play_mid = response_data.get('play_mid', '')
            like_avg = response_data.get('like_avg', 0)
            share_avg = response_data.get('share_avg', 0)
            comment_avg = response_data.get('comment_avg', 0)
            interact_total = int(like_avg) + int(share_avg) + int(comment_avg)
            avg_duration = response_data.get('avg_duration', '')

            # å®Œæ’­ç‡å’Œäº’åŠ¨ç‡
            play_over_rate = response_data.get('play_over_rate', {})
            play_over_rate_value = play_over_rate.get('value', '') if isinstance(play_over_rate, dict) else ''

            interact_rate = response_data.get('interact_rate', {})
            interact_rate_value = interact_rate.get('value', '') if isinstance(interact_rate, dict) else ''

            # è®¡ç®—CPEå’ŒCPC
            price_20_60 = self.kol_api_data.get('videoPrice', 0)
            cpe_value = None
            cpc_value = None

            if price_20_60 and interact_total:
                try:
                    cpe_value = round(float(price_20_60) / float(interact_total), 2)
                except:
                    pass

            if price_20_60 and play_mid:
                try:
                    cpc_value = round(float(price_20_60) / float(play_mid), 2)
                except:
                    pass

            # æ ¹æ®å½“å‰è§†é¢‘ç±»å‹åˆ›å»ºæ•°æ®å¯¹è±¡å¹¶æ·»åŠ åˆ°yingxiao_api_dataæ•°ç»„
            if self.current_video_type == 'xingtu':
                # æ˜Ÿå›¾è§†é¢‘æ•°æ® (douyin_business=1)
                xingtu_data = {
                    'platform_user_id': user_id,
                    'douyin_business': 1,
                    'play_median': play_mid,
                    'interaction_volume': interact_total,
                    'avg_duration': avg_duration,
                    'completion_rate': play_over_rate_value,
                    'interaction_rate': interact_rate_value,
                    'douyin_likes': like_avg,
                    'douyin_shares': share_avg,
                    'douyin_comments': comment_avg,
                    'douyin_cpe': cpe_value,
                    'douyin_cpc': cpc_value
                }
                self.yingxiao_api_data.append(xingtu_data)
                self.logger.info(f"âœ… æ˜Ÿå›¾è§†é¢‘ä¼ æ’­ä¿¡æ¯å·²æ·»åŠ åˆ°yingxiao_api_data (douyin_business=1)")

            elif self.current_video_type == 'personal':
                # ä¸ªäººè§†é¢‘æ•°æ® (douyin_business=0)
                personal_data = {
                    'platform_user_id': user_id,
                    'douyin_business': 0,
                    'play_median': play_mid,
                    'interaction_volume': interact_total,
                    'avg_duration': avg_duration,
                    'completion_rate': play_over_rate_value,
                    'interaction_rate': interact_rate_value,
                    'douyin_likes': like_avg,
                    'douyin_shares': share_avg,
                    'douyin_comments': comment_avg,
                    'douyin_cpe': cpe_value,
                    'douyin_cpc': cpc_value
                }
                self.yingxiao_api_data.append(personal_data)
                self.logger.info(f"âœ… ä¸ªäººè§†é¢‘ä¼ æ’­ä¿¡æ¯å·²æ·»åŠ åˆ°yingxiao_api_data (douyin_business=0)")
            else:
                self.logger.warning(f"æœªçŸ¥çš„è§†é¢‘ç±»å‹: {self.current_video_type}ï¼Œè·³è¿‡ä¿å­˜")

        except Exception as e:
            self.logger.error(f"å¤„ç†ä¼ æ’­ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_audience_distribution(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…å—ä¼—åˆ†å¸ƒAPIæ•°æ®ï¼Œä¿å­˜distributionså­—æ®µä¸ºJSONæ ¼å¼"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†å—ä¼—åˆ†å¸ƒAPIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")
            
            if not response_data:
                self.logger.error("ä½œè€…å—ä¼—åˆ†å¸ƒAPIå“åº”æ•°æ®ä¸ºç©º")
                return

            self.logger.info(f"å—ä¼—åˆ†å¸ƒAPIå“åº”æ•°æ®: {response_data}")

            # æå–distributionså­—æ®µ
            distributions = response_data.get('distributions', [])

            self.logger.info(f"æå–åˆ°çš„distributionsæ•°æ®: {distributions}")

            # å³ä½¿distributionsä¸ºç©ºä¹Ÿè¦ä¿å­˜ï¼Œå› ä¸ºç©ºæ•°æ®ä¹Ÿæ˜¯æœ‰æ•ˆçš„æ•°æ®çŠ¶æ€
            # å°†distributionsè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            try:
                distributions_json = json.dumps(distributions, ensure_ascii=False)
                
                # å­˜å‚¨åˆ°kol_api_dataä¸­ï¼Œç­‰å¾…ç»Ÿä¸€ä¿å­˜
                self.kol_api_data['audience_distribution'] = {
                    'audience_distribution': distributions_json
                }

                self.logger.info(f"å—ä¼—åˆ†å¸ƒå·²å­˜å‚¨åˆ°kol_api_dataï¼Œç­‰å¾…ç»Ÿä¸€ä¿å­˜")

            except Exception as json_error:
                self.logger.error(f"å°†å—ä¼—åˆ†å¸ƒè½¬æ¢ä¸ºJSONæ—¶å‡ºé”™: {str(json_error)}")
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

        except Exception as e:
            self.logger.error(f"å¤„ç†å—ä¼—åˆ†å¸ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_commerce_seed_base_info(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬361-368è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯APIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data:
                self.logger.error("ä½œè€…å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 7. ç§è‰ä»·å€¼
            self.other_api_data['search_after_view_count'] = response_data.get('avg_search_after_view_cnt', '')
            self.other_api_data['search_after_view_rate'] = response_data.get('avg_search_after_view_rate', '')
            self.other_api_data['a3_increase_count'] = response_data.get('avg_a3_incr_cnt', '')
            self.other_api_data['store_entry_cost'] = response_data.get('shop_cost', '')

            self.logger.info(f"âœ… ç§è‰ä»·å€¼ä¿¡æ¯å¤„ç†å®Œæˆï¼šA3å¢é•¿æ•° {self.other_api_data.get('a3_increase_count', '')}")

        except Exception as e:
            self.logger.error(f"å¤„ç†å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_convert_ability(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…è½¬åŒ–èƒ½åŠ›APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬370-380è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†è½¬åŒ–èƒ½åŠ›APIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data:
                self.logger.error("ä½œè€…è½¬åŒ–èƒ½åŠ›APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 8. è½¬åŒ–ä»·å€¼
            video_vv_median = response_data.get('video_vv_median', {})
            if isinstance(video_vv_median, dict):
                self.other_api_data['business_play_median'] = video_vv_median.get('value', '')

            self.other_api_data['component_click_volume'] = response_data.get('component_click_cnt_range', '')
            self.other_api_data['component_click_rate'] = response_data.get('component_click_rate_range', '')
            self.other_api_data['conversion_cpc'] = response_data.get('related_cpc_range', '')

            self.logger.info(f"âœ… è½¬åŒ–ä»·å€¼ä¿¡æ¯å¤„ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"å¤„ç†è½¬åŒ–èƒ½åŠ›æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_link_card(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒAPIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬382-391è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒAPIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data or 'link_struct' not in response_data:
                self.logger.warning("è¿æ¥ç”¨æˆ·åˆ†å¸ƒAPIå“åº”æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘link_structå­—æ®µ")
                return

            # 9. è¿æ¥ç”¨æˆ·åˆ†å¸ƒ
            link_struct = response_data['link_struct']
            if isinstance(link_struct, dict):
                self.other_api_data['aware_user_count'] = link_struct.get('1', {}).get('value', '')
                self.other_api_data['interest_user_cost'] = link_struct.get('2', {}).get('value', '')
                self.other_api_data['like_user_count'] = link_struct.get('3', {}).get('value', '')
                self.other_api_data['connected_user_count'] = link_struct.get('5', {}).get('value', '')

            self.logger.info(f"âœ… è¿æ¥ç”¨æˆ·åˆ†å¸ƒå¤„ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_fans_distribution(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ç²‰ä¸æ•°æ®åˆ†å¸ƒAPIæ•°æ® - è§£ææˆJSONæ ¼å¼"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†ç²‰ä¸æ•°æ®åˆ†å¸ƒAPIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data or 'distributions' not in response_data:
                self.logger.warning("ç²‰ä¸æ•°æ®åˆ†å¸ƒAPIå“åº”æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘distributionså­—æ®µ")
                return

            distributions = response_data['distributions']

            # åˆå§‹åŒ–JSONå¯¹è±¡
            age_distribution = []  # å¹´é¾„åˆ†å¸ƒï¼ˆæ•°ç»„ï¼‰
            region_distribution = []  # åœ°åŸŸåˆ†å¸ƒï¼ˆæ•°ç»„ï¼‰
            crowd_distribution = []  # å…«å¤§äººç¾¤åˆ†å¸ƒï¼ˆæ•°ç»„ï¼‰

            for dist in distributions:
                dist_type = dist.get('type')
                distribution_list = dist.get('distribution_list', [])

                # æ€§åˆ«åˆ†å¸ƒ type=1
                if dist_type == 1:
                    # ç¡®ä¿è½¬æ¢ä¸ºæ•°å­—ç±»å‹
                    total = sum([float(item.get('distribution_value', 0)) for item in distribution_list])
                    for item in distribution_list:
                        key = item.get('distribution_key')
                        value = float(item.get('distribution_value', 0))
                        if key == 'male' and total > 0:
                            self.other_api_data['male_fan_ratio'] = f"{round(value / total * 100, 2)}%"
                        elif key == 'female' and total > 0:
                            self.other_api_data['female_fan_ratio'] = f"{round(value / total * 100, 2)}%"

                # å¹´é¾„åˆ†å¸ƒ type=2 - è½¬æˆæ•°ç»„æ ¼å¼
                elif dist_type == 2:
                    total = sum([float(item.get('distribution_value', 0)) for item in distribution_list])
                    if total > 0:
                        for item in distribution_list:
                            age_range = item.get('distribution_key', '')
                            value = float(item.get('distribution_value', 0))
                            if age_range:
                                percentage = round(value / total * 100, 2)
                                age_distribution.append({
                                    'age_range': age_range,
                                    'percentage': percentage
                                })

                # åœ°åŸŸåˆ†å¸ƒ type=4 - è½¬æˆJSONæ•°ç»„
                elif dist_type == 4:
                    total = sum([float(item.get('distribution_value', 0)) for item in distribution_list])
                    if total > 0:
                        for item in distribution_list:
                            region_name = item.get('distribution_key', '')
                            value = float(item.get('distribution_value', 0))
                            if region_name:
                                percentage = round(value / total * 100, 2)
                                region_distribution.append({
                                    'region': region_name,
                                    'percentage': percentage
                                })
                        # æŒ‰å æ¯”é™åºæ’åº
                        region_distribution.sort(key=lambda x: x['percentage'], reverse=True)

                # å…«å¤§äººç¾¤åˆ†å¸ƒ type=1024 - è½¬æˆæ•°ç»„æ ¼å¼
                elif dist_type == 1024:
                    total = sum([float(item.get('distribution_value', 0)) for item in distribution_list])
                    if total > 0:
                        for item in distribution_list:
                            crowd_name = item.get('distribution_key', '')
                            value = float(item.get('distribution_value', 0))
                            if crowd_name:
                                percentage = round(value / total * 100, 2)
                                crowd_distribution.append({
                                    'crowd_type': crowd_name,
                                    'percentage': percentage
                                })

                # ä½äºå æ¯” type=256 - æ·»åŠ åˆ°å…«å¤§äººç¾¤æ•°ç»„æœ«å°¾
                elif dist_type == 256:
                    description = dist.get('description', '')
                    if description:
                        crowd_distribution.append({
                            'crowd_type': 'below_average_description',
                            'description': description
                        })

            # å°†JSONæ•°ç»„è½¬ä¸ºå­—ç¬¦ä¸²å­˜å‚¨
            if age_distribution:
                self.other_api_data['old_ratio'] = json.dumps(age_distribution, ensure_ascii=False)

            if region_distribution:
                self.other_api_data['region_distribution'] = json.dumps(region_distribution, ensure_ascii=False)

            if crowd_distribution:
                self.other_api_data['below_ratio'] = json.dumps(crowd_distribution, ensure_ascii=False)

        except Exception as e:
            self.logger.error(f"å¤„ç†ç²‰ä¸æ•°æ®åˆ†å¸ƒæ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def setup_logger(self):
        """è®¾ç½®æ—¥å¿—é…ç½®ï¼Œæ”¯æŒexeæ‰“åŒ…"""
        # è®¾ç½®æ—¥å¿—ç›®å½•
        base_path = get_base_path()
        log_path = os.path.join(base_path, 'logs')
        os.makedirs(log_path, exist_ok=True)

        # ç§»é™¤é»˜è®¤å¤„ç†å™¨ï¼Œé¿å…é‡å¤è¾“å‡º
        logger.remove()

        # æ·»åŠ æ§åˆ¶å°è¾“å‡º
        logger.add(
            sys.stdout,
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            level="INFO"
        )

        # æ·»åŠ æ–‡ä»¶è¾“å‡º
        logger.add(
            os.path.join(log_path, "pgy_{time:YYYY-MM-DD}.log"),
            rotation="1 day",
            retention="7 days",
            format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
            level="DEBUG",
            encoding="utf-8"
        )

    def setup_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        # å¦‚æœæµè§ˆå™¨å·²ç»åˆå§‹åŒ–ï¼Œç›´æ¥è¿”å›
        if self.browser and self.context and self.page:
            self.logger.info("æµè§ˆå™¨å·²ç»åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return

        # è®¾ç½®playwrightæµè§ˆå™¨è·¯å¾„ï¼Œæ”¯æŒexeæ‰“åŒ…
        base_path = get_base_path()
        playwright_browsers_path = os.path.join(base_path, 'ms-playwright')

        # è®¾ç½®ç¯å¢ƒå˜é‡
        if os.path.exists(playwright_browsers_path):
            os.environ['PLAYWRIGHT_BROWSERS_PATH'] = playwright_browsers_path
            self.logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰æµè§ˆå™¨è·¯å¾„: {playwright_browsers_path}")
        else:
            self.logger.warning(f"æœªæ‰¾åˆ°è‡ªå®šä¹‰æµè§ˆå™¨è·¯å¾„: {playwright_browsers_path}")

        self.playwright = sync_playwright().start()
        # é…ç½®æµè§ˆå™¨é€‰é¡¹
        self.browser = self.playwright.chromium.launch(
            headless=False,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-gpu',
                '--no-sandbox',
                '--disable-dev-shm-usage',
            ]
        )
        # åˆ›å»ºä¸Šä¸‹æ–‡
        self.context = self.browser.new_context(
            viewport={
                'width': 1512,
                'height': 768
            },
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
        )

        # å°è¯•åŠ è½½å·²ä¿å­˜çš„Cookie
        if self._load_cookies():
            # éªŒè¯Cookieæ˜¯å¦æœ‰æ•ˆ
            self.page = self.context.new_page()
            try:
                self.page.goto(self.base_url)
                self.common.random_sleep(2, 3)

                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç”¨æˆ·å¤´åƒå…ƒç´ 
                self.logger.info("éªŒè¯Cookieæ˜¯å¦æœ‰æ•ˆ...")
                
                login_detected = False

                try:
                    element = self.page.locator(".user-avatar")
                    count = element.count()
                    self.logger.info(f"é€‰æ‹©å™¨ '{".user-avatar"}' æ‰¾åˆ° {count} ä¸ªå…ƒç´ ")

                    if count > 0:
                        # æ£€æŸ¥æ‰€æœ‰å…ƒç´ ï¼Œåªè¦æœ‰ä¸€ä¸ªå¯è§å°±è®¤ä¸ºç™»å½•æˆåŠŸ
                        self.logger.info(f"å¼€å§‹æ£€æŸ¥ {count} ä¸ª .user-avatar å…ƒç´ çš„å¯è§æ€§...")
                        all_elements = element.all()
                        for i, elem in enumerate(all_elements):
                            try:
                                if elem.is_visible(timeout=1000):
                                    self.logger.info(f"ç¬¬ {i+1} ä¸ª .user-avatar å…ƒç´ å¯è§ï¼ŒCookieæœ‰æ•ˆ")
                                    login_detected = True
                                    break
                                else:
                                    self.logger.debug(f"ç¬¬ {i+1} ä¸ª .user-avatar å…ƒç´ ä¸å¯è§")
                            except Exception as elem_error:
                                self.logger.debug(f"ç¬¬ {i+1} ä¸ª .user-avatar å…ƒç´ æ£€æŸ¥å‡ºé”™: {str(elem_error)}")
                                continue

                        if not login_detected:
                            self.logger.warning(f"æ‰¾åˆ° {count} ä¸ª .user-avatar å…ƒç´ ï¼Œä½†éƒ½ä¸å¯è§")
                except Exception as e:
                    self.logger.debug(f"é€‰æ‹©å™¨ '{".user-avatar"}' æ£€æŸ¥å‡ºé”™: {str(e)}")
                
                # æ›´æ–°ç™»å½•çŠ¶æ€
                if login_detected:
                    self.is_logged_in = True
                    self.logger.info("Cookieæœ‰æ•ˆï¼Œå·²è‡ªåŠ¨ç™»å½•")
                else:
                    self.logger.info("Cookieå·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å½•")
                    self.is_logged_in = False
            except Exception as e:
                self.logger.warning(f"CookieéªŒè¯å¤±è´¥: {str(e)}")
                self.logger.info("å°†è¿›è¡Œé‡æ–°ç™»å½•")
                self.is_logged_in = False
        else:
            self.page = self.context.new_page()
            self.is_logged_in = False

        # è®¾ç½®é¡µé¢è¶…æ—¶æ—¶é—´
        self.page.set_default_timeout(20000)
        # è®¾ç½®å“åº”ç›‘å¬
        self.page.on("response", self._handle_api_response)

        self.logger.info("æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")

    def login(self):
        """
        ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•ï¼Œæœ€å¤šç­‰å¾…5åˆ†é’Ÿ
        å‚è€ƒå°çº¢ä¹¦ç™»å½•æ£€æµ‹é€»è¾‘ï¼Œä½¿ç”¨wait_for_selector
        """
        try:

            if self.page is None:
                self.logger.info("æµè§ˆå™¨æœªåˆå§‹åŒ–ï¼Œå¼€å§‹åˆå§‹åŒ–...")
                self.setup_browser()

            if self.is_logged_in:
                self.logger.info("å·²å¤„äºç™»å½•çŠ¶æ€")
                return True

            try:
                # è®¿é—®é¦–é¡µ
                self.page.goto(self.base_url)
                self.logger.info("ç­‰å¾…ç™»å½•æˆåŠŸæ ‡è¯†å‡ºç°...")
                self.common.random_sleep(20, 30)
                # å°è¯•å¤šä¸ªå¯èƒ½çš„é€‰æ‹©å™¨
                selectors = [
                    ".text-avatar",           # æŠ–éŸ³å¤´åƒ
                    ".user-avatar",           # é€šç”¨å¤´åƒ
                ]
                
                # è®¾ç½®æœ€å¤§ç­‰å¾…æ—¶é—´(5åˆ†é’Ÿ)
                max_wait_time = 300  # ç§’
                start_time = time.time()
                login_detected = False
                
                # å¾ªç¯æ£€æŸ¥ç›´åˆ°æ‰¾åˆ°å…ƒç´ æˆ–è¶…æ—¶
                while time.time() - start_time < max_wait_time:
                    # æ¯30ç§’æç¤ºä¸€æ¬¡ç­‰å¾…çŠ¶æ€
                    elapsed_time = int(time.time() - start_time)
                    if elapsed_time % 30 == 0 and elapsed_time > 0:
                        self.logger.info(f"â³ ç­‰å¾…ç™»å½•ä¸­... å·²ç­‰å¾… {elapsed_time} ç§’")
                    
                    # å°è¯•æ¯ä¸ªé€‰æ‹©å™¨
                    for selector in selectors:
                        try:
                            # æ£€æŸ¥å…ƒç´ æ˜¯å¦å¯è§ï¼Œè®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
                            element = self.page.locator(selector)
                            if element.count() > 0:
                                if element.first.is_visible(timeout=2000):
                                    self.logger.info(f"âœ… é€šè¿‡é€‰æ‹©å™¨ '{selector}' æ£€æµ‹åˆ°ç™»å½•æˆåŠŸï¼")
                                    login_detected = True
                                    break
                        except Exception as e:
                            # å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªé€‰æ‹©å™¨
                            pass
                    
                    # å¦‚æœæ‰¾åˆ°ç™»å½•æ ‡è¯†ï¼Œé€€å‡ºå¾ªç¯
                    if login_detected:
                        break
                    
                    
                    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†æ£€æŸ¥
                    time.sleep(2)
                
                # æ£€æŸ¥æ˜¯å¦ç™»å½•æˆåŠŸ
                if login_detected:
                    self.is_logged_in = True
                    
                    # ç™»å½•æˆåŠŸåä¿å­˜Cookie
                    self._save_cookies()
                    
                    self.logger.info("ğŸ‰ ç™»å½•æˆåŠŸï¼å·²ä¿å­˜Cookie")
                    return True
                else:
                    # è¶…æ—¶æœªæ£€æµ‹åˆ°ç™»å½•
                    self.logger.error("âŒ ç­‰å¾…ç™»å½•è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ï¼Œç¨‹åºé€€å‡º")
                    return False

            except Exception as e:
                self.logger.error(f"ç­‰å¾…ç™»å½•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {str(e)}")
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                return False

        except Exception as e:
            self.logger.error(f"ç™»å½•è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            return False

    def close(self):
        """
        å…³é—­æµè§ˆå™¨ã€playwrightå’Œæ•°æ®åº“è¿æ¥
        """
        try:
            # ä¿å­˜Cookie
            if self.is_logged_in:
                self._save_cookies()

            # æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦å·²åˆå§‹åŒ–
            if hasattr(self, 'page') and self.page:
                self.page.close()
            if hasattr(self, 'context') and self.context:
                self.context.close()
            if hasattr(self, 'browser') and self.browser:
                self.browser.close()
            if hasattr(self, 'playwright') and self.playwright:
                self.playwright.stop()

            self.logger.info("æµè§ˆå™¨å’Œplaywrightå·²å…³é—­")
        except Exception as e:
            self.logger.error(f"å…³é—­èµ„æºæ—¶å‡ºé”™: {str(e)}")

    def update_monitor_status(self, **kwargs):
        """æ›´æ–°ç›‘æ§çŠ¶æ€"""
        self.logger.debug(f"æ›´æ–°ç›‘æ§çŠ¶æ€: {kwargs}")
        if kwargs.get('completed_count'):
            self.monitor_data['completed_count'] = kwargs.get('completed_count')
        if kwargs.get('fail_count'):
            self.monitor_data['fail_count'] = kwargs.get('fail_count')

    def save_data(self, user_id: str, data: List[Dict[str, Any]]):
        """
        ä¿å­˜æŠ“å–çš„æ•°æ®åˆ°CSVæ–‡ä»¶
        """
        try:
            filename = os.path.join(self.data_dir, f'user_{user_id}_{datetime.now().strftime("%Y%m%d")}.csv')
            df = pd.DataFrame(data)
            df.to_csv(filename, index=False, encoding='utf-8')
            self.logger.info(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")

    def _check_api_response_status(self, response_data: Dict[str, Any], url: str) -> bool:
        """æ£€æŸ¥APIå“åº”çŠ¶æ€ï¼Œè¿”å›Trueè¡¨ç¤ºçŠ¶æ€å¼‚å¸¸éœ€è¦è·³è¿‡å¤„ç†"""
        try:
            if response_data and 'base_resp' in response_data:
                base_resp = response_data.get('base_resp', {})
                status_code = base_resp.get('status_code')
                status_message = base_resp.get('status_message', '')
                
                if status_code == 10005:
                    self.logger.warning(f"APIè¿”å›ç™»å½•å¤±æ•ˆ: {status_message}, URL: {url}")
                    return True
                elif status_code != 0 and status_code is not None:
                    self.logger.warning(f"APIè¿”å›é”™è¯¯çŠ¶æ€: {status_code} - {status_message}, URL: {url}")
                    return True
            
            return False  # çŠ¶æ€æ­£å¸¸ï¼Œå¯ä»¥ç»§ç»­å¤„ç†
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥APIå“åº”çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
            return False

    def _handle_api_response(self, response):
        """å¤„ç†APIå“åº” - åªå¤„ç†æŒ‡å®šçš„APIæ¥å£"""
        try:
            url = response.url

            # å®šä¹‰éœ€è¦å¤„ç†çš„ç›®æ ‡APIåˆ—è¡¨
            target_apis = [
                '/api/author/get_author_base_info', #è¯¦ç»†ä¿¡æ¯
                '/api/data_sp/check_author_display', #ç²‰ä¸èµè—æ•°
                '/api/author/get_author_marketing_info', #æŠ¥ä»·
                '/api/author/get_author_platform_channel_info_v2', #æŠ¥ä»·
                '/api/aggregator/get_author_commerce_spread_info',  # é¢„ä¼°CPE/CPM
                '/api/data_sp/get_author_spread_info',  # ä¼ æ’­ä»·å€¼
                '/api/aggregator/get_author_commerce_seed_base_info',  # ç§è‰ä»·å€¼
                '/api/data_sp/get_author_convert_ability',  # è½¬åŒ–ä»·å€¼
                '/api/data_sp/author_link_card',  # è¿æ¥ç”¨æˆ·åˆ†å¸ƒ
                '/api/data_sp/get_author_fans_distribution',  # ç²‰ä¸æ•°æ®
            ]

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡API
            is_target_api = any(api in url for api in target_apis)
            if not is_target_api:
                return

            # åªå¤„ç†XHRæˆ–fetchè¯·æ±‚
            if response.request.resource_type not in ['xhr', 'fetch']:
                if '/api/data_sp/get_author_spread_info' in url:
                    self.logger.warning(f"âŒ spread_info APIè¢«è¿‡æ»¤ï¼šèµ„æºç±»å‹ = {response.request.resource_type}")
                return

            try:
                # æ£€æŸ¥é¡µé¢çŠ¶æ€
                if self.page.is_closed():
                    if '/api/data_sp/get_author_spread_info' in url:
                        self.logger.warning(f"âŒ spread_info APIè¢«è¿‡æ»¤ï¼šé¡µé¢å·²å…³é—­")
                    return

                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status != 200:
                    self.logger.warning(f"APIå“åº”çŠ¶æ€å¼‚å¸¸: {response.status}, URL: {url}")
                    return

                # è§£æå“åº”æ•°æ®
                response_data = response.json()

                # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
                if not response_data or not isinstance(response_data, dict):
                    self.logger.warning(f"APIå“åº”æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {url}")
                    return

                # æ£€æŸ¥APIå“åº”çŠ¶æ€
                if self._check_api_response_status(response_data, url):
                    if '/api/data_sp/get_author_spread_info' in url:
                        self.logger.warning(f"âŒ spread_info APIè¢«è¿‡æ»¤ï¼šå“åº”çŠ¶æ€å¼‚å¸¸")
                    return  # å¦‚æœçŠ¶æ€å¼‚å¸¸ï¼Œç›´æ¥è¿”å›

                # ç¡®å®šåŒ¹é…çš„APIç±»å‹
                matched_api = None
                for api in target_apis:
                    if api in url:
                        matched_api = api
                        break

                # å­˜å‚¨APIæ•°æ®ï¼ˆç”¨äºé¦–é¡µåŠ è½½æ—¶çš„æ‰¹å¤„ç†ï¼‰
                self.api_data[url] = {
                    'url': url,
                    'data': response_data,
                    'api_type': matched_api,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'status': response.status
                }

                # éªŒè¯å½“å‰æ˜¯å¦æœ‰æ­£åœ¨å¤„ç†çš„ç”¨æˆ·
                if not self.current_kol or not self.current_kol.get('user_id'):
                    return

            except Exception as e:
                if '/api/data_sp/get_author_spread_info' in url:
                    self.logger.error(f"âŒ å¤„ç† spread_info APIæ—¶å‡ºé”™: {str(e)}")
                self.logger.error(f"å¤„ç†APIæ•°æ®æ—¶å‡ºé”™: {str(e)}, URL: {url}")
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

        except Exception as e:
            self.logger.error(f"å¤„ç†APIå“åº”æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _save_cookies(self):
        """
        ä¿å­˜å½“å‰ä¼šè¯çš„Cookieåˆ°åŒçº§ç›®å½•
        """
        try:
            cookies = self.context.cookies()
            # ç¡®ä¿cookieæ–‡ä»¶çš„ç›®å½•å­˜åœ¨
            cookie_dir = os.path.dirname(self.cookie_file)
            if cookie_dir and not os.path.exists(cookie_dir):
                os.makedirs(cookie_dir, exist_ok=True)

            with open(self.cookie_file, 'w', encoding='utf-8') as f:
                json.dump(cookies, f, indent=2, ensure_ascii=False)
            logger.info(f"Cookieå·²ä¿å­˜åˆ°: {self.cookie_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜Cookieæ—¶å‡ºé”™: {str(e)}")

    def _load_cookies(self):
        """
        ä»åŒçº§ç›®å½•åŠ è½½ä¿å­˜çš„Cookie
        :return: æ˜¯å¦æˆåŠŸåŠ è½½Cookie
        """
        try:
            if os.path.exists(self.cookie_file):
                with open(self.cookie_file, 'r', encoding='utf-8') as f:
                    cookies = json.load(f)

                if cookies:
                    self.context.add_cookies(cookies)
                    logger.info(f"å·²æˆåŠŸåŠ è½½ {len(cookies)} ä¸ªCookie")
                    return True
                else:
                    logger.warning("Cookieæ–‡ä»¶ä¸ºç©º")
                    return False
            else:
                return False
        except Exception as e:
            logger.error(f"åŠ è½½Cookieæ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœcookieæ–‡ä»¶æŸåï¼Œåˆ é™¤å®ƒ
            try:
                if os.path.exists(self.cookie_file):
                    os.remove(self.cookie_file)
                    logger.info("å·²åˆ é™¤æŸåçš„Cookieæ–‡ä»¶")
            except:
                pass
            return False


def get_pending_kols() -> List[Dict[str, Any]]:
    """è·å–éœ€è¦å¤„ç†çš„KOLåˆ—è¡¨"""
    try:
        api_url = f"https://tianji.fangpian999.com/api/admin/creatorBusiness/getNewerCreator?type=1&platform_id=2"
        headers = {"Content-Type": "application/json"}

        response = requests.post(api_url, headers=headers, timeout=30, verify=False)
        creator_data = response.json()['data']
        print(f"ä»æ•°æ®åº“è·å–åˆ° {len(creator_data)} ä¸ªå¾…å¤„ç†çš„KOL")
        return creator_data
    except Exception as e:
        print(f"è·å–KOLåˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        raise


def process_kol(spider: DouYinSpider, kol: Dict[str, Any]):
    """å¤„ç†å•ä¸ªKOL"""
    # ä»attribute_datasä¸­æå–KOLåç§°å’Œæ„å»ºé“¾æ¥
    try:
        kol_name = kol['creator_nickname']
        star_id = kol['platform_user_id']
        douyin_link = f"https://www.xingtu.cn/ad/creator/author-homepage/douyin-video/{star_id}"

        if not kol_name:
            spider.logger.warning(f"æ— æ³•ä»attribute_datasä¸­è·å–KOLåç§°ï¼Œä½¿ç”¨star_id: {star_id}")
            kol_name = f"KOL_{star_id}"
    except (json.JSONDecodeError, AttributeError) as e:
        spider.logger.error(f"è§£æattribute_dataså¤±è´¥: {str(e)}")
        return False

    try:
        spider.logger.info(f"å¼€å§‹å¤„ç†KOL: {kol_name}")

        # éªŒè¯å¿…è¦çš„å­—æ®µ
        if not star_id:
            spider.logger.warning(f"KOL {kol_name} ç¼ºå°‘star_idï¼Œè·³è¿‡å¤„ç†")
            return False

        # æ‰§è¡ŒæŠ“å–
        result = spider.scrape_user_notes(kol_name, douyin_link, star_id)

        if result == 1:
            spider.logger.info(f"âœ… KOL {kol_name} å¤„ç†æˆåŠŸ")
            return True
        else:
            # å¤„ç†å¤±è´¥
            spider.logger.warning(f"âš ï¸ KOL {kol_name} å¤„ç†å¤±è´¥")
            return False

    except Exception as e:
        spider.logger.error(f"âŒ å¤„ç†KOL {kol_name} æ—¶å‡ºé”™: {str(e)}")
        spider.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return False


def run_spider_task():
    """
    æ‰§è¡Œçˆ¬è™«ä»»åŠ¡ - å•æ¬¡æ‰§è¡Œç‰ˆæœ¬
    """
    spider = None
    try:
        print("=== æŠ–éŸ³KOLæ•°æ®æŠ“å–ç¨‹åºå¯åŠ¨ ===")

        # 1. è·å–å¾…å¤„ç†çš„KOLåˆ—è¡¨
        kols = get_pending_kols()
        if not kols:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„KOLæ•°æ®ï¼Œç­‰å¾…ä¸‹æ¬¡æŸ¥è¯¢...")
            return True

        # 2. åˆå§‹åŒ–çˆ¬è™«
        spider = DouYinSpider()
        spider.setup_browser()

        # 3. ç™»å½•
        login_success = spider.login()
        if not login_success:
            print("ç™»å½•å¤±è´¥ï¼Œç­‰å¾…ä¸‹æ¬¡é‡è¯•...")
            return False

        # 4. æ‰¹å¤„ç†KOL
        processed_count = 0
        failed_count = 0

        for i, kol in enumerate(kols, 1):
            # ä¸å†æ£€æŸ¥æ•°æ®åº“ä¸­çš„è®°å½•ï¼Œç›´æ¥å¤„ç†æ‰€æœ‰KOL
            print(f"è¿›åº¦: {i}/{len(kols)} ({(i / len(kols)) * 100:.1f}%)")

            try:
                result = process_kol(spider, kol)
                if result:
                    processed_count += 1
                    # æ³¨æ„ï¼šè¿™é‡Œä¸å†æ£€æŸ¥statuså­—æ®µï¼Œå› ä¸ºkolç°åœ¨æ˜¯å­—å…¸ç±»å‹
                else:
                    failed_count += 1

                # æ¯ä¸ªKOLä¹‹é—´ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                if i < len(kols):  # æœ€åä¸€ä¸ªKOLä¸éœ€è¦ç­‰å¾…
                    wait_time = random.randint(15, 20)
                    print(f"ç­‰å¾… {wait_time} ç§’åå¤„ç†ä¸‹ä¸€ä¸ªKOL...")
                    time.sleep(wait_time)

            except KeyboardInterrupt:
                print("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
                break
            except Exception as e:
                print(f"æ‰¹å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°æœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
                failed_count += 1
                continue

        # 5. è¾“å‡ºå¤„ç†ç»“æœç»Ÿè®¡
        print("=" * 60)
        print("ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
        print(f"æ€»æ•°é‡: {len(kols)}")
        print(f"æˆåŠŸå¤„ç†: {processed_count}")
        print(f"å¤„ç†å¤±è´¥: {failed_count}")
        print(f"æˆåŠŸç‡: {(processed_count / len(kols) * 100):.1f}%")
        print("=" * 60)

        return failed_count == 0  # å¦‚æœæ²¡æœ‰å¤±è´¥çš„åˆ™è¿”å›True

    except KeyboardInterrupt:
        print("âš ï¸ ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­ç¨‹åº")
        return False
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return False
    finally:
        # ç¡®ä¿èµ„æºè¢«æ­£ç¡®é‡Šæ”¾
        if spider:
            try:
                spider.close()
                print("èµ„æºæ¸…ç†å®Œæˆ")
            except Exception as e:
                print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {str(e)}")


def main():
    """
    ä¸»å‡½æ•° - åªåœ¨å¼‚å¸¸æ—¶é‡å¯ç‰ˆæœ¬
    """
    try:
        # åŠ è½½é…ç½®
        config = load_config()
        scheduler_config = config['SCHEDULER_CONFIG']

        logger.info("=== è’²å…¬è‹±æ•°æ®æŠ“å–ç¨‹åºå¯åŠ¨ ===")
        logger.info(f"æ‰§è¡Œæ—¶é—´: æ¯å¤© {scheduler_config['daily_time']}")

        if scheduler_config['run_once']:
            success = run_spider_task()
            if not success:
                logger.info("ç¨‹åºå¼‚å¸¸åœæ­¢ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
                time.sleep(3600)
                return main()  # é€’å½’é‡å¯
            return success

        elif scheduler_config['enable_scheduler']:
            # æ³¨å†Œå®šæ—¶ä»»åŠ¡
            schedule.every().day.at(scheduler_config['daily_time']).do(run_spider_task)

            # è¿è¡Œè°ƒåº¦å™¨
            logger.info("è°ƒåº¦å™¨å¼€å§‹è¿è¡Œ...")
            while True:
                try:
                    schedule.run_pending()
                    time.sleep(scheduler_config['check_interval'])
                except Exception as e:
                    logger.error(f"è°ƒåº¦å™¨è¿è¡Œå‡ºé”™: {str(e)}")
                    logger.info("è°ƒåº¦å™¨å¼‚å¸¸åœæ­¢ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
                    time.sleep(3600)
                    return main()  # é‡å¯æ•´ä¸ªç¨‹åº

        else:
            # è°ƒåº¦å™¨æœªå¯ç”¨ï¼Œç›´æ¥æ‰§è¡Œä¸€æ¬¡
            success = run_spider_task()
            if not success:
                logger.info("ç¨‹åºå¼‚å¸¸åœæ­¢ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
                time.sleep(3600)
                return main()  # é€’å½’é‡å¯
            return success

    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        return True
    except Exception as e:
        logger.error(f"ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        logger.info("ç¨‹åºå¯åŠ¨å¼‚å¸¸ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
        time.sleep(3600)
        return main()  # é€’å½’é‡å¯


if __name__ == "__main__":
    try:
        success = main()
        if success:
            logger.info("ç¨‹åºæ‰§è¡ŒæˆåŠŸ")
            sys.exit(0)
        else:
            logger.error("ç¨‹åºæ‰§è¡Œå¤±è´¥")
            sys.exit(1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        sys.exit(1)