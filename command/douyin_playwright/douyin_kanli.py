import configparser
import json
import os
import time
import random
from datetime import datetime
import sys
from typing import Optional, Dict, Any, List
import traceback

import playwright
import requests
import urllib3

import pandas as pd
import schedule
from loguru import logger
from playwright.sync_api import sync_playwright
from unitl.common import Common

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

"""
    è·å–æŠ–éŸ³åšä¸»çš„æœˆæ€»è¥æ”¶
"""


# é…ç½®å¸¸é‡
def get_base_path():
    """è·å–åŸºç¡€è·¯å¾„ï¼Œæ”¯æŒexeæ‰“åŒ…"""
    try:
        return os.path.dirname(os.path.abspath(sys.argv[0])) if hasattr(sys, '_MEIPASS') else os.path.dirname(
            os.path.abspath(__file__))
    except Exception:
        return os.path.abspath("../..")

def get_resource_path(relative_path):
    """è·å–èµ„æºæ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒexeæ‰“åŒ…"""
    try:
        # PyInstalleråˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹å¹¶å°†è·¯å¾„å­˜å‚¨åœ¨_MEIPASSä¸­
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath("../../WeekAccountUpdate")
    return os.path.join(base_path, relative_path)

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config = configparser.ConfigParser()

    # å°è¯•å¤šä¸ªå¯èƒ½çš„é…ç½®æ–‡ä»¶è·¯å¾„
    config_paths = [
        get_resource_path('WeekAccountUpdate/config.ini'),
        get_resource_path('config.ini'),
        'WeekAccountUpdate/config.ini',
        'config.ini'
    ]

    config_loaded = False
    for config_path in config_paths:
        if os.path.exists(config_path):
            config.read(config_path, encoding='utf-8')
            config_loaded = True
            break

    if not config_loaded:
        logger.error("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶")
        raise FileNotFoundError("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")

    # è§£æé…ç½®
    return {
        'SCHEDULER_CONFIG': {
            'enable_scheduler': config.getboolean('SCHEDULER', 'enable_scheduler'),
            'daily_time': config.get('SCHEDULER', 'daily_time'),
            'run_once': config.getboolean('SCHEDULER', 'run_once'),
            'check_interval': config.getint('SCHEDULER', 'check_interval')
        }
    }

class DouYinSpider:
    def __init__(self):
        self.setup_logger()
        # è®¾ç½®loggerå±æ€§
        self.logger = logger
        # è®¾ç½®cookieå’Œæ•°æ®ç›®å½•ï¼Œæ”¯æŒexeæ‰“åŒ…
        base_path = get_base_path()
        self.cookie_file = os.path.join(base_path, 'cookies.json')
        self.data_dir = os.path.join(base_path, 'data')
        os.makedirs(self.data_dir, exist_ok=True)
        self.base_url = "https://www.xingtu.cn/ad/creator/index"
        self.is_logged_in = False
        self.found_match = False  # æ·»åŠ æ ‡å¿—ä½ä½œä¸ºç±»å±æ€§
        self.api_data = {}  # å­˜å‚¨APIæ•°æ®
        self.common = Common()
        self.current_kol: Optional[Dict[str, str, str]] = None  # å½“å‰æ­£åœ¨å¤„ç†çš„KOLä¿¡æ¯
        self.processed_api_responses = set()  # ç”¨äºè¿½è¸ªå·²å¤„ç†çš„APIå“åº”
        self.marketing_info = {}  # å­˜å‚¨è¥é”€ä¿¡æ¯
        self.last_request_time = 0  # è®°å½•ä¸Šæ¬¡è¯·æ±‚æ—¶é—´
        self.current_video_type = None  # å½“å‰è§†é¢‘ç±»å‹ï¼š'personal' æˆ– 'xingtu'

        # æ–°å¢ï¼šå­˜å‚¨æ‰€æœ‰APIæ•°æ®çš„å­—å…¸ - ç©ºå¯¹è±¡
        self.kol_api_data = {}
        self.other_api_data = {}

        # æµè§ˆå™¨ç›¸å…³å±æ€§åˆå§‹åŒ–
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None

    def scrape_user_notes(self, kol_name: str, kol_url: str, star_id: str) -> int:
        """æŠ“å–æŒ‡å®šKOLçš„ç¬”è®°ä¿¡æ¯å¹¶åŒ¹é…æ›´æ–°æ•°æ®åº“
        è¿”å›å€¼ï¼š
        - 1: å¤„ç†æˆåŠŸï¼ˆæ— è®ºæ˜¯å¦æœ‰è¿æ¥ç”¨æˆ·æŒ‰é’®ï¼Œéƒ½ä¼šå°è¯•è·å–æ‰€æœ‰å¯ç”¨çš„æ•°æ®ï¼‰
        - 0: å¤„ç†å¤±è´¥
        """
        try:
            if not self.is_logged_in:
                self.logger.error("æœªç™»å½•çŠ¶æ€ï¼Œæ— æ³•æŠ“å–æ•°æ®")
                return 0

            user_id = star_id  # å®šä¹‰ user_id ä¾›åç»­ä½¿ç”¨
            self.current_kol = {'name': kol_name, 'url': kol_url, 'user_id':star_id}
            self.processed_api_responses.clear()
            # å®Œå…¨é‡ç½®è¥é”€ä¿¡æ¯ï¼Œç¡®ä¿æ•°æ®éš”ç¦»
            self.marketing_info = {'user_id': star_id}
            # é‡ç½®APIæ•°æ®ç¼“å­˜
            self.api_data = {}
            # é‡æ–°åˆå§‹åŒ–KOLæ•°æ®ç»“æ„ - ç©ºå¯¹è±¡ï¼Œåªå¡«å……åŸºæœ¬ä¿¡æ¯
            self.kol_api_data = {}
            self.other_api_data = {}
            # æ·»åŠ APIå“åº”å¤„ç†æ ‡å¿—
            self.api_response_processed = False

            # ä¸å†åœ¨å¼€å§‹æ—¶åˆ›å»ºè®°å½•ï¼Œç»Ÿä¸€åœ¨æœ€åä¿å­˜æ‰€æœ‰æ•°æ®
            self.page.goto(kol_url, timeout=30000)
            self.logger.info(f"æˆåŠŸè®¿é—®é¡µé¢: {kol_url}")

            try:
                self.page.wait_for_load_state('networkidle', timeout=5000)
            except Exception as e:
                self.logger.warning(f"ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆæ—¶å‡ºé”™: {str(e)}")

            self.common.random_sleep(3, 4)

            api_data_copy = dict(self.api_data)
            for api_url, response_info in api_data_copy.items():
                if 'data' not in response_info:
                    continue
                response_data = response_info['data']  # æå–å®é™…çš„å“åº”æ•°æ®
                if '/api/author/get_author_base_info' in api_url:
                    self._process_author_base_info(response_data)
                elif '/api/data_sp/check_author_display' in api_url:
                    self._process_author_display(response_data)
                elif '/api/author/get_author_marketing_info' in api_url:
                    self._process_marketing_info(response_data)
                elif '/api/author/get_author_platform_channel_info_v2' in api_url:
                    self._process_author_platform_channel_info_v2(response_data)
                elif '/api/aggregator/get_author_commerce_spread_info' in api_url:
                    self._process_author_commerce_info(response_data)



            # ===== æ–°å¢ï¼šç‚¹å‡»å•†ä¸šèƒ½åŠ›å¹¶å¤„ç†è§†é¢‘ç±»å‹ =====
            try:
                self.logger.info("å¼€å§‹å¤„ç†å•†ä¸šèƒ½åŠ›çš„è§†é¢‘ç±»å‹...")

                # ç‚¹å‡»å•†ä¸šèƒ½åŠ›æ ‡ç­¾
                business_ability_tab = self.page.locator("div.el-tabs__nav >> div:has-text('å•†ä¸šèƒ½åŠ›')")
                if business_ability_tab and business_ability_tab.is_visible():
                    self.api_data = {}
                    time.sleep(0.5)
                    business_ability_tab.click()
                    self.logger.info("æˆåŠŸç‚¹å‡»å•†ä¸šèƒ½åŠ›æ ‡ç­¾")
                    time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½

                    # æŸ¥æ‰¾ä¸¤ä¸ªlabelæ ‡ç­¾
                    try:
                        # æ‰¾åˆ°æ‰€æœ‰el-checkbox-buttonæ ‡ç­¾
                        checkbox_buttons = self.page.locator("label.el-checkbox-button.xt-checkbox-button")
                        button_count = checkbox_buttons.count()

                        # æ‰¾åˆ°ä¸ªäººè§†é¢‘å’Œæ˜Ÿå›¾è§†é¢‘æŒ‰é’®
                        personal_video_btn = None
                        xingtu_video_btn = None

                        for i in range(button_count):
                            btn = checkbox_buttons.nth(i)
                            btn_text = btn.inner_text()
                            self.logger.info(f"æŒ‰é’® {i+1} æ–‡æœ¬: {btn_text}")

                            if 'ä¸ªäººè§†é¢‘' in btn_text:
                                personal_video_btn = btn
                                self.logger.info(f"æ‰¾åˆ°ä¸ªäººè§†é¢‘æŒ‰é’®ï¼Œç´¢å¼•: {i}")
                            elif 'æ˜Ÿå›¾è§†é¢‘' in btn_text:
                                xingtu_video_btn = btn
                                self.logger.info(f"æ‰¾åˆ°æ˜Ÿå›¾è§†é¢‘æŒ‰é’®ï¼Œç´¢å¼•: {i}")

                        # æ£€æŸ¥æ˜Ÿå›¾è§†é¢‘æ˜¯å¦è¢«ç¦ç”¨
                        xingtu_disabled = False
                        if xingtu_video_btn:
                            xingtu_class = xingtu_video_btn.get_attribute('class')
                            xingtu_disabled = 'is-disabled' in xingtu_class
                            self.logger.info(f"æ˜Ÿå›¾è§†é¢‘ç¦ç”¨çŠ¶æ€: {xingtu_disabled}, class: {xingtu_class}")

                        if not xingtu_disabled and xingtu_video_btn:
                            # æ˜Ÿå›¾è§†é¢‘æœªç¦ç”¨ï¼Œé»˜è®¤é€‰ä¸­çš„æ˜¯æ˜Ÿå›¾è§†é¢‘
                            self.logger.info("æ˜Ÿå›¾è§†é¢‘æœªç¦ç”¨ï¼Œè·å–æ˜Ÿå›¾è§†é¢‘æ•°æ® (business=1)...")

                            # ç¡®ä¿æ˜Ÿå›¾è§†é¢‘è¢«é€‰ä¸­
                            xingtu_class = xingtu_video_btn.get_attribute('class')
                            if 'is-checked' not in xingtu_class:
                                xingtu_video_btn.click()
                                self.logger.info("ç‚¹å‡»æ˜Ÿå›¾è§†é¢‘æŒ‰é’®")
                                time.sleep(2)

                            # ç­‰å¾…å¹¶æ ‡è®°ä¸ºè·å–æ˜Ÿå›¾è§†é¢‘æ•°æ®
                            self.current_video_type = 'xingtu'  # æ ‡è®°å½“å‰è§†é¢‘ç±»å‹
                            # å¤„ç†é¦–é¡µçš„ spread_info
                            for api_url, response_info in api_data_copy.items():
                                if 'data' not in response_info:
                                    continue
                                response_data = response_info['data']
                                if '/api/data_sp/get_author_spread_info' in api_url:
                                    self._process_author_spread_info(response_data, user_id)
                                    break
                            self.api_data = {}
                            time.sleep(3)  # ç­‰å¾…APIæ•°æ®åŠ è½½

                            # ç‚¹å‡»ä¸ªäººè§†é¢‘
                            if personal_video_btn:
                                self.logger.info("ç‚¹å‡»ä¸ªäººè§†é¢‘æŒ‰é’®...")
                                personal_video_btn.click()
                                time.sleep(2)

                                # æ ‡è®°ä¸ºè·å–ä¸ªäººè§†é¢‘æ•°æ®
                                self.current_video_type = 'personal'
                                for api_url, response_info in api_data_copy.items():
                                    if 'data' not in response_info:
                                        continue
                                    response_data = response_info['data']
                                    if '/api/data_sp/get_author_spread_info' in api_url:
                                        self._process_author_spread_info(response_data, user_id)
                                        break
                                time.sleep(3)  # ç­‰å¾…APIæ•°æ®åŠ è½½
                                self.logger.info("å·²è·å–ä¸ªäººè§†é¢‘æ•°æ® (business=0)")
                        else:
                            # æ˜Ÿå›¾è§†é¢‘è¢«ç¦ç”¨ï¼Œé»˜è®¤æ˜¯ä¸ªäººè§†é¢‘
                            self.logger.info("æ˜Ÿå›¾è§†é¢‘å·²ç¦ç”¨ï¼Œåªè·å–ä¸ªäººè§†é¢‘æ•°æ® (business=0)...")

                            # ç¡®ä¿ä¸ªäººè§†é¢‘è¢«é€‰ä¸­
                            if personal_video_btn:
                                personal_class = personal_video_btn.get_attribute('class')
                                if 'is-checked' not in personal_class:
                                    personal_video_btn.click()
                                    self.logger.info("ç‚¹å‡»ä¸ªäººè§†é¢‘æŒ‰é’®")
                                    time.sleep(2)

                            # æ ‡è®°ä¸ºè·å–ä¸ªäººè§†é¢‘æ•°æ®
                            self.current_video_type = 'personal'
                            time.sleep(3)  # ç­‰å¾…APIæ•°æ®åŠ è½½

                    except Exception as btn_error:
                        self.logger.warning(f"å¤„ç†è§†é¢‘ç±»å‹æŒ‰é’®æ—¶å‡ºé”™: {str(btn_error)}")

                else:
                    # æœªæ‰¾åˆ°å•†ä¸šèƒ½åŠ›æ ‡ç­¾ï¼Œä½¿ç”¨é¦–é¡µé»˜è®¤æ•°æ®
                    self.logger.info("æœªæ‰¾åˆ°å•†ä¸šèƒ½åŠ›æ ‡ç­¾ï¼Œä½¿ç”¨é¦–é¡µé»˜è®¤çš„ä¼ æ’­ä¿¡æ¯æ•°æ®")

                    # é¦–é¡µé»˜è®¤æ˜¯ä¸ªäººè§†é¢‘æ•°æ®
                    self.current_video_type = 'personal'

                    # å¤„ç†é¦–é¡µçš„ spread_info
                    for api_url, response_info in api_data_copy.items():
                        if 'data' not in response_info:
                            continue
                        response_data = response_info['data']
                        if '/api/data_sp/get_author_spread_info' in api_url:
                            self._process_author_spread_info(response_data, user_id)
                            break

            except Exception as ability_error:
                self.logger.warning(f"å¤„ç†å•†ä¸šèƒ½åŠ›æ—¶å‡ºé”™: {str(ability_error)}")

            # ===== å•†ä¸šèƒ½åŠ›å¤„ç†ç»“æŸ =====

            # ç‚¹å‡»è¿æ¥ç”¨æˆ·æ ‡ç­¾
            creative_tab = self.page.locator("div.el-tabs__nav >> div:has-text('è¿æ¥ç”¨æˆ·')")
            if creative_tab and creative_tab.is_visible():
                # ç‚¹å‡»å‰ç­‰å¾…ä¸€ä¸‹ç¡®ä¿å…ƒç´ ç¨³å®š
                time.sleep(0.5)
                creative_tab.click()
                self.logger.info("æˆåŠŸç‚¹å‡»è¿æ¥ç”¨æˆ·æ ‡ç­¾")

                try:
                    self.page.wait_for_load_state('networkidle', timeout=5000)
                except Exception as e:
                    self.logger.warning(f"ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆæ—¶å‡ºé”™: {str(e)}")

                # é¼ æ ‡æ»šè½®å‘ä¸‹æ»šåŠ¨å‡ ä¸‹ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
                self.logger.info("å‘ä¸‹æ»šåŠ¨é¡µé¢ç¡®ä¿å†…å®¹å®Œå…¨åŠ è½½...")
                try:
                    # å‘ä¸‹æ»šåŠ¨3æ¬¡ï¼Œæ¯æ¬¡æ»šåŠ¨500åƒç´ 
                    for i in range(3):
                        self.page.mouse.wheel(0, 500)
                        time.sleep(0.5)  # æ¯æ¬¡æ»šåŠ¨åç­‰å¾…0.5ç§’
                    self.logger.info("é¡µé¢æ»šåŠ¨å®Œæˆ")
                except Exception as e:
                    self.logger.warning(f"é¡µé¢æ»šåŠ¨æ—¶å‡ºé”™: {str(e)}")

                # å°è¯•ç‚¹å‡»ç²‰ä¸ç”»åƒæŒ‰é’®
                self.logger.info("å¼€å§‹ç‚¹å‡»ç²‰ä¸ç”»åƒæŒ‰é’®...")

                # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½ï¼Œç¡®ä¿æ‰€æœ‰å…ƒç´ éƒ½å·²æ¸²æŸ“
                self.logger.info("ç­‰å¾…é¡µé¢å…ƒç´ å®Œå…¨åŠ è½½...")
                try:
                    self.page.wait_for_load_state('networkidle', timeout=5000)
                except Exception as e:
                    self.logger.warning(f"ç­‰å¾…é¡µé¢ç½‘ç»œç©ºé—²æ—¶å‡ºé”™: {str(e)}")

                fan_portrait_button = self.page.locator("text=ç²‰ä¸ç”»åƒ")
                if fan_portrait_button and fan_portrait_button.is_visible():
                    time.sleep(0.5)
                    fan_portrait_button.click()
                    try:
                        self.page.wait_for_load_state('networkidle', timeout=5000)
                    except Exception as e:
                        self.logger.warning(f"ç­‰å¾…é¡µé¢ç½‘ç»œç©ºé—²æ—¶å‡ºé”™: {str(e)}")
            print(self.kol_api_data)
            print(self.other_api_data)

            # # ç»Ÿä¸€ä¿å­˜æ‰€æœ‰æ”¶é›†åˆ°çš„APIæ•°æ®åˆ°è¿œç¨‹æ¥å£
            # if self.current_kol and self.current_kol.get('user_id'):
            #     self.logger.info("å¼€å§‹ç»Ÿä¸€ä¿å­˜æ‰€æœ‰APIæ•°æ®åˆ°è¿œç¨‹æ¥å£")
            #     self._save_all_kol_data_to_api(self.current_kol.get('user_id'))
            #     self.logger.info("âœ… æ‰€æœ‰APIæ•°æ®å·²ç»Ÿä¸€ä¿å­˜åˆ°è¿œç¨‹æ¥å£")

            return 1  # è¿”å›1è¡¨ç¤ºå¤„ç†æˆåŠŸ

        except Exception as e:
            self.logger.error(f"æŠ“å–KOL {kol_name} ç¬”è®°æ—¶å‡ºé”™: {str(e)}")
            raise



    def _save_all_kol_data_to_api(self, user_id: str):
        """ç»Ÿä¸€ä¿å­˜æ‰€æœ‰æ”¶é›†åˆ°çš„APIæ•°æ®åˆ°è¿œç¨‹æ¥å£"""
        try:
            self.logger.info(f"å¼€å§‹ç»Ÿä¸€ä¿å­˜æ‰€æœ‰APIæ•°æ®åˆ°è¿œç¨‹æ¥å£ï¼Œç”¨æˆ·ID: {user_id}")

            # åˆå¹¶ other_api_data åˆ° kol_api_dataï¼ˆother_api_data åŒ…å«æ‰€æœ‰å•†ä¸šèƒ½åŠ›å’Œè¿æ¥ç”¨æˆ·çš„æ•°æ®ï¼‰
            self.logger.info("åˆå¹¶ other_api_data åˆ° kol_api_data...")
            self.kol_api_data.update(self.other_api_data)

            # æ‰“å°æ‰€æœ‰æ”¶é›†åˆ°çš„æ•°æ®
            self.logger.info("=" * 70)
            self.logger.info("ğŸ“Š å·²æ”¶é›†çš„æ‰€æœ‰KOLæ•°æ®å­—æ®µ:")
            self.logger.info("=" * 70)
            for key, value in self.kol_api_data.items():
                self.logger.info(f"  {key}: {value}")
            self.logger.info("=" * 70)

            # ç›´æ¥ä½¿ç”¨æ‰å¹³åŒ–çš„kol_api_data
            # æ„å»ºpayloadï¼Œå‚è€ƒget_pgy_intro.pyçš„æ ¼å¼
            payload = {
                "apis": [
                    {
                        "tb_name": "douyin_kol_data",
                        "tb_data": [self.kol_api_data]
                    }
                ],
                "client_id": 1
            }

            self.logger.info(f"å‡†å¤‡å‘é€æ•°æ®åˆ°APIæ¥å£")

            # å‘é€POSTè¯·æ±‚åˆ°APIæ¥å£
            api_url = "http://47.104.76.46:19000/api/v1/sync/spider/data"
            headers = {
                "Content-Type": "application/json"
            }

            response = requests.post(api_url, json=payload, headers=headers, timeout=30, verify=False)

            if response.status_code == 200:
                try:
                    response_data = response.json()
                    if response_data.get('code') == 200:
                        self.logger.info(f"âœ… æ•°æ®æˆåŠŸå‘é€åˆ°APIæ¥å£ï¼Œå“åº”: {response_data}")
                    else:
                        self.logger.error(f"âŒ APIæ¥å£è¯·æ±‚å¤±è´¥ï¼ŒAPIè¿”å›é”™è¯¯: {response_data}")
                        raise Exception(f"APIæ¥å£è¯·æ±‚å¤±è´¥: {response_data}")
                except ValueError:
                    self.logger.error(f"APIè¿”å›éJSONå“åº”: {response.text[:200]}")
                    raise Exception(f"APIè¿”å›éJSONå“åº”")
            else:
                self.logger.error(f"âŒ APIæ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                self.logger.error(f"å“åº”å†…å®¹: {response.text}")
                raise Exception(f"APIæ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")

        except Exception as api_error:
            self.logger.error(f"ç»Ÿä¸€ä¿å­˜APIæ•°æ®åˆ°è¿œç¨‹æ¥å£æ—¶å‡ºé”™: {str(api_error)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise

    def _process_marketing_info(self, response_data: Dict[str, Any]):
        """å¤„ç†è¥é”€ä¿¡æ¯æ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬255-269è¡Œ"""
        try:
            if not response_data:
                self.logger.error("è¥é”€ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 3. æŠ¥ä»·
            if 'price_info' in response_data:
                price_list = response_data['price_info']
                for price in price_list:
                    video_type = price.get('video_type')
                    price_value = price.get('price', 0)
                    if video_type == 1:
                        self.other_api_data['price_first'] = price_value
                    elif video_type == 2:
                        self.other_api_data['price_two'] = price_value
                        self.kol_api_data['picture_price'] = price_value
                        self.kol_api_data['video_price'] = price_value
                    elif video_type == 71:
                        self.other_api_data['price_three'] = price_value
                    elif video_type == 150:
                        self.other_api_data['price_four'] = price_value

            self.logger.info(f"âœ… æŠ¥ä»·ä¿¡æ¯å¤„ç†å®Œæˆï¼š20-60sæŠ¥ä»· {self.kol_api_data.get('20-60sæŠ¥ä»·', '')}")

        except Exception as e:
            self.logger.error(f"å¤„ç†è¥é”€ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_base_info(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…åŸºæœ¬ä¿¡æ¯æ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬226-247è¡Œ"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…åŸºæœ¬ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # æ€§åˆ«è½¬æ¢
            gender = response_data.get('gender', '')
            if gender == 1:
                gender = 2
            elif gender == 2:
                gender = 1
            # 1. åŸºæœ¬ä¿¡æ¯
            self.kol_api_data['creator_nickname'] = response_data.get('nick_name', '')
            self.kol_api_data['platform_user_id'] = response_data.get('id')
            self.kol_api_data['creator_location'] = response_data.get('city')
            self.kol_api_data['creator_gender'] = gender
            tags_relation = response_data.get('tags_relation', {})
            if tags_relation:
                self.kol_api_data['content_field'] = list(tags_relation.keys()) if tags_relation else ''

            self.other_api_data['sec_uid'] = response_data.get('sec_uid', '')

            self.logger.info(f"âœ… åŸºæœ¬ä¿¡æ¯å¤„ç†å®Œæˆï¼š{self.kol_api_data.get('è¾¾äººæ˜µç§°', '')}")

        except Exception as e:
            self.logger.error(f"å¤„ç†ä½œè€…åŸºæœ¬ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_display(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…æ˜¾ç¤ºæ£€æŸ¥APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬249-253è¡Œ"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…æ˜¾ç¤ºæ£€æŸ¥APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 2. ç²‰ä¸æ•°èµè—
            self.kol_api_data['fans_count'] = response_data.get('follower', '')
            self.kol_api_data['like_collect_count'] = response_data.get('link_cnt', '')

            self.logger.info(f"âœ… ç²‰ä¸æ•°æ®å¤„ç†å®Œæˆï¼šç²‰ä¸ {self.kol_api_data.get('ç²‰ä¸æ•°', '')}")

        except Exception as e:
            self.logger.error(f"å¤„ç†ä½œè€…æ˜¾ç¤ºæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_platform_channel_info_v2(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…é“¾æ¥ç»“æ„APIæ•°æ®ï¼Œä¿å­˜link_structå¯¹è±¡ä¸ºJSONæ ¼å¼"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…é“¾æ¥ç»“æ„APIå“åº”æ•°æ®ä¸ºç©º")
                return

            self.kol_api_data['creator_intro'] = response_data.get('self_intro', {})

        except Exception as e:
            self.logger.error(f"å¤„ç†é“¾æ¥ç»“æ„æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_commerce_info(self, response_data: Dict[str, Any]):
        """å¤„ç†ä½œè€…å•†ä¸šä¼ æ’­ä¿¡æ¯APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬349-359è¡Œ"""
        try:
            if not response_data:
                self.logger.error("ä½œè€…å•†ä¸šä¼ æ’­ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 6. é¢„ä¼°CPE/CPM
            self.other_api_data['expect_cpe'] = response_data.get('cpe_20_60', '')
            self.other_api_data['expect_cpm'] = response_data.get('cpm_20_60', '')
            self.other_api_data['platform_hot_rate'] = response_data.get('platform_hot_rate', '')
            self.other_api_data['expect_read'] = response_data.get('vv', '')

            self.logger.info(f"âœ… å•†ä¸šä¼ æ’­ä¿¡æ¯å¤„ç†å®Œæˆï¼šé¢„ä¼°CPE {self.kol_api_data.get('20-60ç§’é¢„ä¼°CPE', '')}")

        except Exception as e:
            self.logger.error(f"å¤„ç†å•†ä¸šä¼ æ’­ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_spread_info(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…ä¼ æ’­ä¿¡æ¯APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬271-347è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†ä¼ æ’­ä¿¡æ¯APIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}ï¼Œè§†é¢‘ç±»å‹: {self.current_video_type}")

            if not response_data:
                self.logger.error("ä½œè€…ä¼ æ’­ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # æå–åŸºç¡€æ•°æ®
            play_mid = response_data.get('play_mid', '')
            like_avg = response_data.get('like_avg', 0)
            share_avg = response_data.get('share_avg', 0)
            comment_avg = response_data.get('comment_avg', 0)
            interact_total = like_avg + share_avg + comment_avg
            avg_duration = response_data.get('avg_duration', '')

            # å®Œæ’­ç‡å’Œäº’åŠ¨ç‡
            play_over_rate = response_data.get('play_over_rate', {})
            play_over_rate_value = play_over_rate.get('value', '') if isinstance(play_over_rate, dict) else ''

            interact_rate = response_data.get('interact_rate', {})
            interact_rate_value = interact_rate.get('value', '') if isinstance(interact_rate, dict) else ''

            # æ ¹æ®å½“å‰è§†é¢‘ç±»å‹å¡«å……ä¸åŒçš„å­—æ®µåˆ° other_api_data
            if self.current_video_type == 'xingtu':
                # 4. ä¼ æ’­ä»·å€¼(æ˜Ÿå›¾)
                self.other_api_data['business_play_volume'] = play_mid
                self.other_api_data['business_interaction_volume'] = interact_total
                self.other_api_data['business_avg_duration'] = avg_duration
                self.other_api_data['business_completion_rate'] = play_over_rate_value
                self.other_api_data['business_interaction_rate'] = interact_rate_value
                self.other_api_data['business_likes'] = like_avg
                self.other_api_data['business_shares'] = share_avg
                self.other_api_data['business_comments'] = comment_avg

                # è®¡ç®—CPEå’ŒCPCï¼ˆä½¿ç”¨ video_price å­—æ®µï¼‰
                price_20_60 = self.kol_api_data.get('video_price', 0)
                if price_20_60 and interact_total:
                    try:
                        self.other_api_data['business_cpe'] = round(float(price_20_60) / float(interact_total), 2)
                    except:
                        pass

                if price_20_60 and play_mid:
                    try:
                        self.other_api_data['business_cpc'] = round(float(price_20_60) / float(play_mid), 2)
                    except:
                        pass

                self.logger.info(f"âœ… æ˜Ÿå›¾è§†é¢‘ä¼ æ’­ä¿¡æ¯å·²å¡«å…… (business=1)")

            elif self.current_video_type == 'personal':
                # 5. ä¼ æ’­ä»·å€¼(æ—¥å¸¸)
                self.other_api_data['daily_play_volume'] = play_mid
                self.other_api_data['daily_interaction_volume'] = interact_total
                self.other_api_data['daily_avg_duration'] = avg_duration
                self.other_api_data['daily_completion_rate'] = play_over_rate_value
                self.other_api_data['daily_interaction_rate'] = interact_rate_value
                self.other_api_data['daily_likes'] = like_avg
                self.other_api_data['daily_shares'] = share_avg
                self.other_api_data['daily_comments'] = comment_avg

                # è®¡ç®—CPEå’ŒCPCï¼ˆä½¿ç”¨ video_price å­—æ®µï¼‰
                price_20_60 = self.kol_api_data.get('video_price', 0)
                if price_20_60 and interact_total:
                    try:
                        self.other_api_data['daily_cpe'] = round(float(price_20_60) / float(interact_total), 2)
                    except:
                        pass

                if price_20_60 and play_mid:
                    try:
                        self.other_api_data['daily_cpc'] = round(float(price_20_60) / float(play_mid), 2)
                    except:
                        pass

                self.logger.info(f"âœ… ä¸ªäººè§†é¢‘ä¼ æ’­ä¿¡æ¯å·²å¡«å…… (business=0)")
            else:
                self.logger.warning(f"æœªçŸ¥çš„è§†é¢‘ç±»å‹: {self.current_video_type}ï¼Œè·³è¿‡ä¿å­˜")

        except Exception as e:
            self.logger.error(f"å¤„ç†ä¼ æ’­ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_audience_distribution(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…å—ä¼—åˆ†å¸ƒAPIæ•°æ®ï¼Œä¿å­˜distributionså­—æ®µä¸ºJSONæ ¼å¼"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†å—ä¼—åˆ†å¸ƒAPIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")
            
            if not response_data:
                self.logger.error("ä½œè€…å—ä¼—åˆ†å¸ƒAPIå“åº”æ•°æ®ä¸ºç©º")
                return

            self.logger.info(f"å—ä¼—åˆ†å¸ƒAPIå“åº”æ•°æ®: {response_data}")

            # æå–distributionså­—æ®µ
            distributions = response_data.get('distributions', [])

            self.logger.info(f"æå–åˆ°çš„distributionsæ•°æ®: {distributions}")

            # å³ä½¿distributionsä¸ºç©ºä¹Ÿè¦ä¿å­˜ï¼Œå› ä¸ºç©ºæ•°æ®ä¹Ÿæ˜¯æœ‰æ•ˆçš„æ•°æ®çŠ¶æ€
            # å°†distributionsè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            try:
                distributions_json = json.dumps(distributions, ensure_ascii=False)
                
                # å­˜å‚¨åˆ°kol_api_dataä¸­ï¼Œç­‰å¾…ç»Ÿä¸€ä¿å­˜
                self.kol_api_data['audience_distribution'] = {
                    'audience_distribution': distributions_json
                }

                self.logger.info(f"å—ä¼—åˆ†å¸ƒå·²å­˜å‚¨åˆ°kol_api_dataï¼Œç­‰å¾…ç»Ÿä¸€ä¿å­˜")

            except Exception as json_error:
                self.logger.error(f"å°†å—ä¼—åˆ†å¸ƒè½¬æ¢ä¸ºJSONæ—¶å‡ºé”™: {str(json_error)}")
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

        except Exception as e:
            self.logger.error(f"å¤„ç†å—ä¼—åˆ†å¸ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_commerce_seed_base_info(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬361-368è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯APIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data:
                self.logger.error("ä½œè€…å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 7. ç§è‰ä»·å€¼
            self.other_api_data['search_after_view_count'] = response_data.get('avg_search_after_view_cnt', '')
            self.other_api_data['search_after_view_rate'] = response_data.get('avg_search_after_view_rate', '')
            self.other_api_data['a3_increase_count'] = response_data.get('avg_a3_incr_cnt', '')
            self.other_api_data['store_entry_cost'] = response_data.get('shop_cost', '')

            self.logger.info(f"âœ… ç§è‰ä»·å€¼ä¿¡æ¯å¤„ç†å®Œæˆï¼šA3å¢é•¿æ•° {self.other_api_data.get('a3_increase_count', '')}")

        except Exception as e:
            self.logger.error(f"å¤„ç†å•†ä¸šç§å­åŸºç¡€ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_convert_ability(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ä½œè€…è½¬åŒ–èƒ½åŠ›APIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬370-380è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†è½¬åŒ–èƒ½åŠ›APIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data:
                self.logger.error("ä½œè€…è½¬åŒ–èƒ½åŠ›APIå“åº”æ•°æ®ä¸ºç©º")
                return

            # 8. è½¬åŒ–ä»·å€¼
            video_vv_median = response_data.get('video_vv_median', {})
            if isinstance(video_vv_median, dict):
                self.other_api_data['business_play_median'] = video_vv_median.get('value', '')

            self.other_api_data['component_click_volume'] = response_data.get('component_click_cnt_range', '')
            self.other_api_data['component_click_rate'] = response_data.get('component_click_rate_range', '')
            self.other_api_data['conversion_cpc'] = response_data.get('related_cpc_range', '')

            self.logger.info(f"âœ… è½¬åŒ–ä»·å€¼ä¿¡æ¯å¤„ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"å¤„ç†è½¬åŒ–èƒ½åŠ›æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_link_card(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒAPIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬382-391è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒAPIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data or 'link_struct' not in response_data:
                self.logger.warning("è¿æ¥ç”¨æˆ·åˆ†å¸ƒAPIå“åº”æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘link_structå­—æ®µ")
                return

            # 9. è¿æ¥ç”¨æˆ·åˆ†å¸ƒ
            link_struct = response_data['link_struct']
            if isinstance(link_struct, dict):
                self.other_api_data['aware_user_count'] = link_struct.get('1', {}).get('value', '')
                self.other_api_data['interest_user_cost'] = link_struct.get('2', {}).get('value', '')
                self.other_api_data['like_user_count'] = link_struct.get('3', {}).get('value', '')
                self.other_api_data['connected_user_count'] = link_struct.get('5', {}).get('value', '')

            self.logger.info(f"âœ… è¿æ¥ç”¨æˆ·åˆ†å¸ƒå¤„ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"å¤„ç†è¿æ¥ç”¨æˆ·åˆ†å¸ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _process_author_fans_distribution(self, response_data: Dict[str, Any], user_id: str):
        """å¤„ç†ç²‰ä¸æ•°æ®åˆ†å¸ƒAPIæ•°æ® - å‚è€ƒget_douyin_guakao.pyç¬¬393-443è¡Œ"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†ç²‰ä¸æ•°æ®åˆ†å¸ƒAPIæ•°æ®ï¼Œç”¨æˆ·ID: {user_id}")

            if not response_data or 'distributions' not in response_data:
                self.logger.warning("ç²‰ä¸æ•°æ®åˆ†å¸ƒAPIå“åº”æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘distributionså­—æ®µ")
                return

            # 10. ç²‰ä¸æ•°æ®
            distributions = response_data['distributions']

            for dist in distributions:
                dist_type = dist.get('type')
                distribution_list = dist.get('distribution_list', [])

                # æ€§åˆ«åˆ†å¸ƒ type=1
                if dist_type == 1:
                    total = sum([item.get('distribution_value', 0) for item in distribution_list])
                    for item in distribution_list:
                        key = item.get('distribution_key')
                        value = item.get('distribution_value', 0)
                        if key == 'male' and total > 0:
                            self.other_api_data['male_fan_ratio'] = f"{round(value / total * 100, 2)}%"
                        elif key == 'female' and total > 0:
                            self.other_api_data['female_fan_ratio'] = f"{round(value / total * 100, 2)}%"

                # å¹´é¾„åˆ†å¸ƒ type=2
                elif dist_type == 2:
                    total = sum([item.get('distribution_value', 0) for item in distribution_list])
                    if total > 0:
                        for item in distribution_list:
                            key = item.get('distribution_key', '')
                            value = item.get('distribution_value', 0)
                            if key:
                                percentage = round(value / total * 100, 2)
                                self.other_api_data[f'age_{key}'] = f"{percentage}%"

                # åœ°åŸŸåˆ†å¸ƒ type=4
                elif dist_type == 4:
                    total = sum([item.get('distribution_value', 0) for item in distribution_list])
                    if total > 0:
                        region_list = []
                        for item in distribution_list:
                            key = item.get('distribution_key', '')
                            value = item.get('distribution_value', 0)
                            if key:
                                percentage = round(value / total * 100, 2)
                                region_list.append((key, percentage))

                        # æŒ‰å æ¯”é™åºæ’åº
                        region_list.sort(key=lambda x: x[1], reverse=True)

                        # æ‹¼æ¥æˆå­—ç¬¦ä¸²
                        region_str = 'ã€'.join([f"{region}:{pct}%" for region, pct in region_list])
                        self.other_api_data['region_distribution'] = region_str

                # å…«å¤§äººç¾¤åˆ†å¸ƒ type=1024
                elif dist_type == 1024:
                    total = sum([item.get('distribution_value', 0) for item in distribution_list])
                    if total > 0:
                        for item in distribution_list:
                            key = item.get('distribution_key', '')
                            value = item.get('distribution_value', 0)
                            if key:
                                percentage = round(value / total * 100, 2)
                                self.other_api_data[f'crowd_{key}'] = f"{percentage}%"

                # ä½äºå æ¯” type=256
                elif dist_type == 256:
                    self.other_api_data['below_ratio'] = dist.get('description', '')

            self.logger.info(f"âœ… ç²‰ä¸æ•°æ®åˆ†å¸ƒå¤„ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"å¤„ç†ç²‰ä¸æ•°æ®åˆ†å¸ƒæ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def setup_logger(self):
        """è®¾ç½®æ—¥å¿—é…ç½®ï¼Œæ”¯æŒexeæ‰“åŒ…"""
        # è®¾ç½®æ—¥å¿—ç›®å½•
        base_path = get_base_path()
        log_path = os.path.join(base_path, 'logs')
        os.makedirs(log_path, exist_ok=True)

        # ç§»é™¤é»˜è®¤å¤„ç†å™¨ï¼Œé¿å…é‡å¤è¾“å‡º
        logger.remove()

        # æ·»åŠ æ§åˆ¶å°è¾“å‡º
        logger.add(
            sys.stdout,
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            level="INFO"
        )

        # æ·»åŠ æ–‡ä»¶è¾“å‡º
        logger.add(
            os.path.join(log_path, "pgy_{time:YYYY-MM-DD}.log"),
            rotation="1 day",
            retention="7 days",
            format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
            level="DEBUG",
            encoding="utf-8"
        )

    def setup_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        # å¦‚æœæµè§ˆå™¨å·²ç»åˆå§‹åŒ–ï¼Œç›´æ¥è¿”å›
        if self.browser and self.context and self.page:
            self.logger.info("æµè§ˆå™¨å·²ç»åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return

        # è®¾ç½®playwrightæµè§ˆå™¨è·¯å¾„ï¼Œæ”¯æŒexeæ‰“åŒ…
        base_path = get_base_path()
        playwright_browsers_path = os.path.join(base_path, 'ms-playwright')

        # è®¾ç½®ç¯å¢ƒå˜é‡
        if os.path.exists(playwright_browsers_path):
            os.environ['PLAYWRIGHT_BROWSERS_PATH'] = playwright_browsers_path
            self.logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰æµè§ˆå™¨è·¯å¾„: {playwright_browsers_path}")
        else:
            self.logger.warning(f"æœªæ‰¾åˆ°è‡ªå®šä¹‰æµè§ˆå™¨è·¯å¾„: {playwright_browsers_path}")

        self.playwright = sync_playwright().start()
        # é…ç½®æµè§ˆå™¨é€‰é¡¹
        self.browser = self.playwright.chromium.launch(
            headless=False,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-gpu',
                '--no-sandbox',
                '--disable-dev-shm-usage',
            ]
        )
        # åˆ›å»ºä¸Šä¸‹æ–‡
        self.context = self.browser.new_context(
            viewport={
                'width': 1512,
                'height': 768
            },
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
        )

        # å°è¯•åŠ è½½å·²ä¿å­˜çš„Cookie
        if self._load_cookies():
            # éªŒè¯Cookieæ˜¯å¦æœ‰æ•ˆ
            self.page = self.context.new_page()
            try:
                self.page.goto(self.base_url)
                self.common.random_sleep(2, 3)

                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç”¨æˆ·å¤´åƒå…ƒç´ 
                self.logger.info("éªŒè¯Cookieæ˜¯å¦æœ‰æ•ˆ...")
                
                login_detected = False

                try:
                    element = self.page.locator(".user-avatar")
                    count = element.count()
                    self.logger.info(f"é€‰æ‹©å™¨ '{".user-avatar"}' æ‰¾åˆ° {count} ä¸ªå…ƒç´ ")

                    if count > 0:
                        # æ£€æŸ¥æ‰€æœ‰å…ƒç´ ï¼Œåªè¦æœ‰ä¸€ä¸ªå¯è§å°±è®¤ä¸ºç™»å½•æˆåŠŸ
                        self.logger.info(f"å¼€å§‹æ£€æŸ¥ {count} ä¸ª .user-avatar å…ƒç´ çš„å¯è§æ€§...")
                        all_elements = element.all()
                        for i, elem in enumerate(all_elements):
                            try:
                                if elem.is_visible(timeout=1000):
                                    self.logger.info(f"ç¬¬ {i+1} ä¸ª .user-avatar å…ƒç´ å¯è§ï¼ŒCookieæœ‰æ•ˆ")
                                    login_detected = True
                                    break
                                else:
                                    self.logger.debug(f"ç¬¬ {i+1} ä¸ª .user-avatar å…ƒç´ ä¸å¯è§")
                            except Exception as elem_error:
                                self.logger.debug(f"ç¬¬ {i+1} ä¸ª .user-avatar å…ƒç´ æ£€æŸ¥å‡ºé”™: {str(elem_error)}")
                                continue

                        if not login_detected:
                            self.logger.warning(f"æ‰¾åˆ° {count} ä¸ª .user-avatar å…ƒç´ ï¼Œä½†éƒ½ä¸å¯è§")
                except Exception as e:
                    self.logger.debug(f"é€‰æ‹©å™¨ '{".user-avatar"}' æ£€æŸ¥å‡ºé”™: {str(e)}")
                
                # æ›´æ–°ç™»å½•çŠ¶æ€
                if login_detected:
                    self.is_logged_in = True
                    self.logger.info("Cookieæœ‰æ•ˆï¼Œå·²è‡ªåŠ¨ç™»å½•")
                else:
                    self.logger.info("Cookieå·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å½•")
                    self.is_logged_in = False
            except Exception as e:
                self.logger.warning(f"CookieéªŒè¯å¤±è´¥: {str(e)}")
                self.logger.info("å°†è¿›è¡Œé‡æ–°ç™»å½•")
                self.is_logged_in = False
        else:
            self.page = self.context.new_page()
            self.is_logged_in = False

        # è®¾ç½®é¡µé¢è¶…æ—¶æ—¶é—´
        self.page.set_default_timeout(20000)
        # è®¾ç½®å“åº”ç›‘å¬
        self.page.on("response", self._handle_api_response)

        self.logger.info("æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")

    def login(self):
        """
        ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•ï¼Œæœ€å¤šç­‰å¾…5åˆ†é’Ÿ
        å‚è€ƒå°çº¢ä¹¦ç™»å½•æ£€æµ‹é€»è¾‘ï¼Œä½¿ç”¨wait_for_selector
        """
        try:

            if self.page is None:
                self.logger.info("æµè§ˆå™¨æœªåˆå§‹åŒ–ï¼Œå¼€å§‹åˆå§‹åŒ–...")
                self.setup_browser()

            if self.is_logged_in:
                self.logger.info("å·²å¤„äºç™»å½•çŠ¶æ€")
                return True

            try:
                # è®¿é—®é¦–é¡µ
                self.page.goto(self.base_url)
                self.logger.info("ç­‰å¾…ç™»å½•æˆåŠŸæ ‡è¯†å‡ºç°...")
                self.common.random_sleep(20, 30)
                # å°è¯•å¤šä¸ªå¯èƒ½çš„é€‰æ‹©å™¨
                selectors = [
                    ".text-avatar",           # æŠ–éŸ³å¤´åƒ
                    ".user-avatar",           # é€šç”¨å¤´åƒ
                ]
                
                # è®¾ç½®æœ€å¤§ç­‰å¾…æ—¶é—´(5åˆ†é’Ÿ)
                max_wait_time = 300  # ç§’
                start_time = time.time()
                login_detected = False
                
                # å¾ªç¯æ£€æŸ¥ç›´åˆ°æ‰¾åˆ°å…ƒç´ æˆ–è¶…æ—¶
                while time.time() - start_time < max_wait_time:
                    # æ¯30ç§’æç¤ºä¸€æ¬¡ç­‰å¾…çŠ¶æ€
                    elapsed_time = int(time.time() - start_time)
                    if elapsed_time % 30 == 0 and elapsed_time > 0:
                        self.logger.info(f"â³ ç­‰å¾…ç™»å½•ä¸­... å·²ç­‰å¾… {elapsed_time} ç§’")
                    
                    # å°è¯•æ¯ä¸ªé€‰æ‹©å™¨
                    for selector in selectors:
                        try:
                            # æ£€æŸ¥å…ƒç´ æ˜¯å¦å¯è§ï¼Œè®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
                            element = self.page.locator(selector)
                            if element.count() > 0:
                                if element.first.is_visible(timeout=2000):
                                    self.logger.info(f"âœ… é€šè¿‡é€‰æ‹©å™¨ '{selector}' æ£€æµ‹åˆ°ç™»å½•æˆåŠŸï¼")
                                    login_detected = True
                                    break
                        except Exception as e:
                            # å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªé€‰æ‹©å™¨
                            pass
                    
                    # å¦‚æœæ‰¾åˆ°ç™»å½•æ ‡è¯†ï¼Œé€€å‡ºå¾ªç¯
                    if login_detected:
                        break
                    
                    
                    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†æ£€æŸ¥
                    time.sleep(2)
                
                # æ£€æŸ¥æ˜¯å¦ç™»å½•æˆåŠŸ
                if login_detected:
                    self.is_logged_in = True
                    
                    # ç™»å½•æˆåŠŸåä¿å­˜Cookie
                    self._save_cookies()
                    
                    self.logger.info("ğŸ‰ ç™»å½•æˆåŠŸï¼å·²ä¿å­˜Cookie")
                    return True
                else:
                    # è¶…æ—¶æœªæ£€æµ‹åˆ°ç™»å½•
                    self.logger.error("âŒ ç­‰å¾…ç™»å½•è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ï¼Œç¨‹åºé€€å‡º")
                    return False

            except Exception as e:
                self.logger.error(f"ç­‰å¾…ç™»å½•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {str(e)}")
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                return False

        except Exception as e:
            self.logger.error(f"ç™»å½•è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            return False

    def close(self):
        """
        å…³é—­æµè§ˆå™¨ã€playwrightå’Œæ•°æ®åº“è¿æ¥
        """
        try:
            # ä¿å­˜Cookie
            if self.is_logged_in:
                self._save_cookies()

            # æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦å·²åˆå§‹åŒ–
            if hasattr(self, 'page') and self.page:
                self.page.close()
            if hasattr(self, 'context') and self.context:
                self.context.close()
            if hasattr(self, 'browser') and self.browser:
                self.browser.close()
            if hasattr(self, 'playwright') and self.playwright:
                self.playwright.stop()

            self.logger.info("æµè§ˆå™¨å’Œplaywrightå·²å…³é—­")
        except Exception as e:
            self.logger.error(f"å…³é—­èµ„æºæ—¶å‡ºé”™: {str(e)}")

    def update_monitor_status(self, **kwargs):
        """æ›´æ–°ç›‘æ§çŠ¶æ€"""
        self.logger.debug(f"æ›´æ–°ç›‘æ§çŠ¶æ€: {kwargs}")
        if kwargs.get('completed_count'):
            self.monitor_data['completed_count'] = kwargs.get('completed_count')
        if kwargs.get('fail_count'):
            self.monitor_data['fail_count'] = kwargs.get('fail_count')

    def save_data(self, user_id: str, data: List[Dict[str, Any]]):
        """
        ä¿å­˜æŠ“å–çš„æ•°æ®åˆ°CSVæ–‡ä»¶
        """
        try:
            filename = os.path.join(self.data_dir, f'user_{user_id}_{datetime.now().strftime("%Y%m%d")}.csv')
            df = pd.DataFrame(data)
            df.to_csv(filename, index=False, encoding='utf-8')
            self.logger.info(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")

    def _check_api_response_status(self, response_data: Dict[str, Any], url: str) -> bool:
        """æ£€æŸ¥APIå“åº”çŠ¶æ€ï¼Œè¿”å›Trueè¡¨ç¤ºçŠ¶æ€å¼‚å¸¸éœ€è¦è·³è¿‡å¤„ç†"""
        try:
            if response_data and 'base_resp' in response_data:
                base_resp = response_data.get('base_resp', {})
                status_code = base_resp.get('status_code')
                status_message = base_resp.get('status_message', '')
                
                if status_code == 10005:
                    self.logger.warning(f"APIè¿”å›ç™»å½•å¤±æ•ˆ: {status_message}, URL: {url}")
                    return True
                elif status_code != 0 and status_code is not None:
                    self.logger.warning(f"APIè¿”å›é”™è¯¯çŠ¶æ€: {status_code} - {status_message}, URL: {url}")
                    return True
            
            return False  # çŠ¶æ€æ­£å¸¸ï¼Œå¯ä»¥ç»§ç»­å¤„ç†
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥APIå“åº”çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
            return False

    def _handle_api_response(self, response):
        """å¤„ç†APIå“åº” - åªå¤„ç†æŒ‡å®šçš„APIæ¥å£"""
        try:
            url = response.url

            # å®šä¹‰éœ€è¦å¤„ç†çš„ç›®æ ‡APIåˆ—è¡¨
            target_apis = [
                '/api/author/get_author_base_info', #è¯¦ç»†ä¿¡æ¯
                '/api/data_sp/check_author_display', #ç²‰ä¸èµè—æ•°
                '/api/author/get_author_marketing_info', #æŠ¥ä»·
                '/api/author/get_author_platform_channel_info_v2', #æŠ¥ä»·
                '/api/aggregator/get_author_commerce_spread_info',  # é¢„ä¼°CPE/CPM
                '/api/data_sp/get_author_spread_info',  # ä¼ æ’­ä»·å€¼
                '/api/aggregator/get_author_commerce_seed_base_info',  # ç§è‰ä»·å€¼
                '/api/data_sp/get_author_convert_ability',  # è½¬åŒ–ä»·å€¼
                '/api/data_sp/author_link_card',  # è¿æ¥ç”¨æˆ·åˆ†å¸ƒ
                '/api/data_sp/get_author_fans_distribution',  # ç²‰ä¸æ•°æ®
            ]

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡API
            is_target_api = any(api in url for api in target_apis)
            if not is_target_api:
                return

            # åªå¤„ç†XHRæˆ–fetchè¯·æ±‚
            if response.request.resource_type not in ['xhr', 'fetch']:
                return

            try:
                # æ£€æŸ¥é¡µé¢çŠ¶æ€
                if self.page.is_closed():
                    return

                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status != 200:
                    self.logger.warning(f"APIå“åº”çŠ¶æ€å¼‚å¸¸: {response.status}, URL: {url}")
                    return

                # è§£æå“åº”æ•°æ®
                response_data = response.json()

                # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
                if not response_data or not isinstance(response_data, dict):
                    self.logger.warning(f"APIå“åº”æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {url}")
                    return

                # æ£€æŸ¥APIå“åº”çŠ¶æ€
                if self._check_api_response_status(response_data, url):
                    return  # å¦‚æœçŠ¶æ€å¼‚å¸¸ï¼Œç›´æ¥è¿”å›

                # ç¡®å®šåŒ¹é…çš„APIç±»å‹
                matched_api = None
                for api in target_apis:
                    if api in url:
                        matched_api = api
                        break

                # å­˜å‚¨APIæ•°æ®ï¼ˆç”¨äºé¦–é¡µåŠ è½½æ—¶çš„æ‰¹å¤„ç†ï¼‰
                self.api_data[url] = {
                    'url': url,
                    'data': response_data,
                    'api_type': matched_api,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'status': response.status
                }

                # éªŒè¯å½“å‰æ˜¯å¦æœ‰æ­£åœ¨å¤„ç†çš„ç”¨æˆ·
                if not self.current_kol or not self.current_kol.get('user_id'):
                    return

            except Exception as e:
                self.logger.error(f"å¤„ç†APIæ•°æ®æ—¶å‡ºé”™: {str(e)}, URL: {url}")
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

        except Exception as e:
            self.logger.error(f"å¤„ç†APIå“åº”æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _save_cookies(self):
        """
        ä¿å­˜å½“å‰ä¼šè¯çš„Cookieåˆ°åŒçº§ç›®å½•
        """
        try:
            cookies = self.context.cookies()
            # ç¡®ä¿cookieæ–‡ä»¶çš„ç›®å½•å­˜åœ¨
            cookie_dir = os.path.dirname(self.cookie_file)
            if cookie_dir and not os.path.exists(cookie_dir):
                os.makedirs(cookie_dir, exist_ok=True)

            with open(self.cookie_file, 'w', encoding='utf-8') as f:
                json.dump(cookies, f, indent=2, ensure_ascii=False)
            logger.info(f"Cookieå·²ä¿å­˜åˆ°: {self.cookie_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜Cookieæ—¶å‡ºé”™: {str(e)}")

    def _load_cookies(self):
        """
        ä»åŒçº§ç›®å½•åŠ è½½ä¿å­˜çš„Cookie
        :return: æ˜¯å¦æˆåŠŸåŠ è½½Cookie
        """
        try:
            if os.path.exists(self.cookie_file):
                with open(self.cookie_file, 'r', encoding='utf-8') as f:
                    cookies = json.load(f)

                if cookies:
                    self.context.add_cookies(cookies)
                    logger.info(f"å·²æˆåŠŸåŠ è½½ {len(cookies)} ä¸ªCookie")
                    return True
                else:
                    logger.warning("Cookieæ–‡ä»¶ä¸ºç©º")
                    return False
            else:
                return False
        except Exception as e:
            logger.error(f"åŠ è½½Cookieæ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœcookieæ–‡ä»¶æŸåï¼Œåˆ é™¤å®ƒ
            try:
                if os.path.exists(self.cookie_file):
                    os.remove(self.cookie_file)
                    logger.info("å·²åˆ é™¤æŸåçš„Cookieæ–‡ä»¶")
            except:
                pass
            return False


def get_pending_kols() -> List[Dict[str, Any]]:
    """è·å–éœ€è¦å¤„ç†çš„KOLåˆ—è¡¨"""
    try:
        api_url = f"https://tianji.fangpian999.com/api/admin/creatorBusiness/getNewerCreator?type=1&platform_id=2"
        headers = {"Content-Type": "application/json"}

        response = requests.post(api_url, headers=headers, timeout=30, verify=False)
        creator_data = response.json()['data']
        print(f"ä»æ•°æ®åº“è·å–åˆ° {len(creator_data)} ä¸ªå¾…å¤„ç†çš„KOL")
        return creator_data
    except Exception as e:
        print(f"è·å–KOLåˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        raise


def process_kol(spider: DouYinSpider, kol: Dict[str, Any]):
    """å¤„ç†å•ä¸ªKOL"""
    # ä»attribute_datasä¸­æå–KOLåç§°å’Œæ„å»ºé“¾æ¥
    try:
        kol_name = kol['creator_nickname']
        star_id = kol['platform_user_id']
        douyin_link = f"https://www.xingtu.cn/ad/creator/author-homepage/douyin-video/{star_id}"

        if not kol_name:
            spider.logger.warning(f"æ— æ³•ä»attribute_datasä¸­è·å–KOLåç§°ï¼Œä½¿ç”¨star_id: {star_id}")
            kol_name = f"KOL_{star_id}"
    except (json.JSONDecodeError, AttributeError) as e:
        spider.logger.error(f"è§£æattribute_dataså¤±è´¥: {str(e)}")
        return False

    try:
        spider.logger.info(f"å¼€å§‹å¤„ç†KOL: {kol_name}")

        # éªŒè¯å¿…è¦çš„å­—æ®µ
        if not star_id:
            spider.logger.warning(f"KOL {kol_name} ç¼ºå°‘star_idï¼Œè·³è¿‡å¤„ç†")
            return False

        # æ‰§è¡ŒæŠ“å–
        result = spider.scrape_user_notes(kol_name, douyin_link, star_id)

        if result == 1:
            spider.logger.info(f"âœ… KOL {kol_name} å¤„ç†æˆåŠŸ")
            return True
        else:
            # å¤„ç†å¤±è´¥
            spider.logger.warning(f"âš ï¸ KOL {kol_name} å¤„ç†å¤±è´¥")
            return False

    except Exception as e:
        spider.logger.error(f"âŒ å¤„ç†KOL {kol_name} æ—¶å‡ºé”™: {str(e)}")
        spider.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return False


def run_spider_task():
    """
    æ‰§è¡Œçˆ¬è™«ä»»åŠ¡ - å•æ¬¡æ‰§è¡Œç‰ˆæœ¬
    """
    spider = None
    try:
        print("=== æŠ–éŸ³KOLæ•°æ®æŠ“å–ç¨‹åºå¯åŠ¨ ===")

        # 1. è·å–å¾…å¤„ç†çš„KOLåˆ—è¡¨
        kols = get_pending_kols()
        if not kols:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„KOLæ•°æ®ï¼Œç­‰å¾…ä¸‹æ¬¡æŸ¥è¯¢...")
            return True

        # 2. åˆå§‹åŒ–çˆ¬è™«
        spider = DouYinSpider()
        spider.setup_browser()

        # 3. ç™»å½•
        login_success = spider.login()
        if not login_success:
            print("ç™»å½•å¤±è´¥ï¼Œç­‰å¾…ä¸‹æ¬¡é‡è¯•...")
            return False

        # 4. æ‰¹å¤„ç†KOL
        processed_count = 0
        failed_count = 0

        for i, kol in enumerate(kols, 1):
            # ä¸å†æ£€æŸ¥æ•°æ®åº“ä¸­çš„è®°å½•ï¼Œç›´æ¥å¤„ç†æ‰€æœ‰KOL
            print(f"è¿›åº¦: {i}/{len(kols)} ({(i / len(kols)) * 100:.1f}%)")

            try:
                result = process_kol(spider, kol)
                if result:
                    processed_count += 1
                    # æ³¨æ„ï¼šè¿™é‡Œä¸å†æ£€æŸ¥statuså­—æ®µï¼Œå› ä¸ºkolç°åœ¨æ˜¯å­—å…¸ç±»å‹
                else:
                    failed_count += 1

                # æ¯ä¸ªKOLä¹‹é—´ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                if i < len(kols):  # æœ€åä¸€ä¸ªKOLä¸éœ€è¦ç­‰å¾…
                    wait_time = random.randint(15, 20)
                    print(f"ç­‰å¾… {wait_time} ç§’åå¤„ç†ä¸‹ä¸€ä¸ªKOL...")
                    time.sleep(wait_time)

            except KeyboardInterrupt:
                print("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
                break
            except Exception as e:
                print(f"æ‰¹å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°æœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
                failed_count += 1
                continue

        # 5. è¾“å‡ºå¤„ç†ç»“æœç»Ÿè®¡
        print("=" * 60)
        print("ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
        print(f"æ€»æ•°é‡: {len(kols)}")
        print(f"æˆåŠŸå¤„ç†: {processed_count}")
        print(f"å¤„ç†å¤±è´¥: {failed_count}")
        print(f"æˆåŠŸç‡: {(processed_count / len(kols) * 100):.1f}%")
        print("=" * 60)

        return failed_count == 0  # å¦‚æœæ²¡æœ‰å¤±è´¥çš„åˆ™è¿”å›True

    except KeyboardInterrupt:
        print("âš ï¸ ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­ç¨‹åº")
        return False
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return False
    finally:
        # ç¡®ä¿èµ„æºè¢«æ­£ç¡®é‡Šæ”¾
        if spider:
            try:
                spider.close()
                print("èµ„æºæ¸…ç†å®Œæˆ")
            except Exception as e:
                print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {str(e)}")


def main():
    """
    ä¸»å‡½æ•° - åªåœ¨å¼‚å¸¸æ—¶é‡å¯ç‰ˆæœ¬
    """
    try:
        # åŠ è½½é…ç½®
        config = load_config()
        scheduler_config = config['SCHEDULER_CONFIG']

        logger.info("=== è’²å…¬è‹±æ•°æ®æŠ“å–ç¨‹åºå¯åŠ¨ ===")
        logger.info(f"æ‰§è¡Œæ—¶é—´: æ¯å¤© {scheduler_config['daily_time']}")

        if scheduler_config['run_once']:
            success = run_spider_task()
            if not success:
                logger.info("ç¨‹åºå¼‚å¸¸åœæ­¢ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
                time.sleep(3600)
                return main()  # é€’å½’é‡å¯
            return success

        elif scheduler_config['enable_scheduler']:
            # æ³¨å†Œå®šæ—¶ä»»åŠ¡
            schedule.every().day.at(scheduler_config['daily_time']).do(run_spider_task)

            # è¿è¡Œè°ƒåº¦å™¨
            logger.info("è°ƒåº¦å™¨å¼€å§‹è¿è¡Œ...")
            while True:
                try:
                    schedule.run_pending()
                    time.sleep(scheduler_config['check_interval'])
                except Exception as e:
                    logger.error(f"è°ƒåº¦å™¨è¿è¡Œå‡ºé”™: {str(e)}")
                    logger.info("è°ƒåº¦å™¨å¼‚å¸¸åœæ­¢ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
                    time.sleep(3600)
                    return main()  # é‡å¯æ•´ä¸ªç¨‹åº

        else:
            # è°ƒåº¦å™¨æœªå¯ç”¨ï¼Œç›´æ¥æ‰§è¡Œä¸€æ¬¡
            success = run_spider_task()
            if not success:
                logger.info("ç¨‹åºå¼‚å¸¸åœæ­¢ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
                time.sleep(3600)
                return main()  # é€’å½’é‡å¯
            return success

    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        return True
    except Exception as e:
        logger.error(f"ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        logger.info("ç¨‹åºå¯åŠ¨å¼‚å¸¸ï¼Œå°†åœ¨1å°æ—¶åé‡å¯...")
        time.sleep(3600)
        return main()  # é€’å½’é‡å¯


if __name__ == "__main__":
    try:
        success = main()
        if success:
            logger.info("ç¨‹åºæ‰§è¡ŒæˆåŠŸ")
            sys.exit(0)
        else:
            logger.error("ç¨‹åºæ‰§è¡Œå¤±è´¥")
            sys.exit(1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        sys.exit(1)