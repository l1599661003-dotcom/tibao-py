"""
è·å–è’²å…¬è‹±é‚€çº¦æ•°æ®
"""

import requests
import urllib3
import time
import sys
import os
import configparser
import schedule
from datetime import datetime
from loguru import logger

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å›ºå®šé…ç½®
# API_BASE_URL = 'http://localhost:5666'
API_BASE_URL = 'https://tianji.fangpian999.com'
PGY_API_URL = 'https://pgy.xiaohongshu.com/api/solar/invite/get_invites_overview'
REQUEST_DELAY = 10  # æ¯æ¬¡è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼‰
REQUEST_TIMEOUT = 30  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_DAYS = 7  # Tokenæœ€å¤§æœ‰æ•ˆå¤©æ•°


def get_resource_path(relative_path):
    """è·å–èµ„æºæ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒexeæ‰“åŒ…"""
    try:
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config = configparser.ConfigParser()
    
    # å°è¯•å¤šä¸ªå¯èƒ½çš„é…ç½®æ–‡ä»¶è·¯å¾„
    config_paths = [
        get_resource_path('pgy_invites_config.ini'),
        'pgy_invites_config.ini',
    ]
    
    config_loaded = False
    for config_path in config_paths:
        if os.path.exists(config_path):
            config.read(config_path, encoding='utf-8')
            config_loaded = True
            logger.info(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            break
    
    if not config_loaded:
        logger.error("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ pgy_invites_config.ini")
        raise FileNotFoundError("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
    
    # åªè§£æè°ƒåº¦å™¨é…ç½®
    return {
        'enable_scheduler': config.getboolean('SCHEDULER', 'enable_scheduler'),
        'daily_time': config.get('SCHEDULER', 'daily_time'),
        'run_once': config.getboolean('SCHEDULER', 'run_once'),
        'check_interval': config.getint('SCHEDULER', 'check_interval'),
    }


def setup_logger():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    # è®¾ç½®æ—¥å¿—ç›®å½•
    if hasattr(sys, '_MEIPASS'):
        exe_dir = os.path.dirname(os.path.abspath(sys.argv[0]))
        log_path = os.path.join(exe_dir, 'logs')
    else:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        log_path = os.path.join(current_dir, 'logs')
    
    os.makedirs(log_path, exist_ok=True)
    
    logger.remove()
    
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
        level="INFO"
    )
    
    logger.add(
        os.path.join(log_path, "pgy_invites_{time:YYYY-MM-DD}.log"),
        rotation="1 day",
        retention="30 days",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}",
        level="DEBUG",
        encoding="utf-8"
    )
    
    logger.info(f"æ—¥å¿—æ–‡ä»¶ä¿å­˜è·¯å¾„: {log_path}")


def check_token_time(update_time):
    """æ£€æŸ¥tokenæ—¶é—´æ˜¯å¦è¶…è¿‡æŒ‡å®šå¤©æ•°"""
    try:
        if isinstance(update_time, str):
            try:
                token_time = datetime.strptime(update_time, '%Y-%m-%d %H:%M:%S')
            except ValueError:
                try:
                    token_time = datetime.strptime(update_time, '%Y-%m-%d')
                except ValueError:
                    return False, 0
        else:
            token_time = datetime.fromtimestamp(update_time)
        
        time_diff = datetime.now() - token_time
        days_diff = time_diff.days
        is_expired = days_diff > MAX_DAYS
        
        return is_expired, days_diff
    except Exception as e:
        logger.warning(f"æ—¶é—´æ£€æŸ¥å‡ºé”™: {str(e)}")
        return False, 0


def get_token_list():
    """è·å–tokenåˆ—è¡¨"""
    try:
        headers = {"Content-Type": "application/json"}
        api_url = f"{API_BASE_URL}/api/admin/spider/token/pgy/list"
        
        response = requests.get(api_url, headers=headers, timeout=REQUEST_TIMEOUT)
        
        if response.status_code != 200:
            logger.error(f"è·å–tokenå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return None
        
        response_json = response.json()
        if 'data' not in response_json:
            logger.error(f"å“åº”æ•°æ®æ ¼å¼é”™è¯¯")
            return None
        
        return response_json['data']
    except Exception as e:
        logger.error(f"è·å–tokenåˆ—è¡¨å‡ºé”™: {str(e)}")
        return None


def check_invite_detail(invite_id):
    """
    æ£€æŸ¥æŒ‡å®šinviteIdæ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“

    Args:
        invite_id: é‚€çº¦ID

    Returns:
        bool: Trueè¡¨ç¤ºå·²å­˜åœ¨ï¼ˆåº”åœæ­¢åˆ†é¡µï¼‰ï¼ŒFalseè¡¨ç¤ºä¸å­˜åœ¨ï¼ˆç»§ç»­åˆ†é¡µï¼‰
    """
    try:
        headers = {"Content-Type": "application/json"}
        api_url = f"{API_BASE_URL}/api/admin/pgyInvites/getPgyInvitesDetail"

        params = {'invite_id': invite_id}

        response = requests.get(
            api_url,
            headers=headers,
            params=params,
            timeout=REQUEST_TIMEOUT
        )

        if response.status_code != 200:
            logger.warning(f"æ£€æŸ¥inviteId {invite_id} å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False

        result = response.json()

        # å¦‚æœè¿”å›æœ‰æ•°æ®ï¼Œè¯´æ˜å·²å­˜åœ¨
        if result.get('data'):
            logger.info(f"âœ… inviteId {invite_id} å·²å­˜åœ¨æ•°æ®åº“ï¼Œåœæ­¢åˆ†é¡µ")
            return True
        else:
            logger.debug(f"inviteId {invite_id} ä¸å­˜åœ¨ï¼Œç»§ç»­åˆ†é¡µ")
            return False

    except Exception as e:
        logger.warning(f"æ£€æŸ¥inviteId {invite_id} å‡ºé”™: {str(e)}")
        return False


def get_invites_data(token_content, platform_user_id):
    """
    è·å–é‚€çº¦æ•°æ®ï¼ˆæ”¯æŒå¤šé¡µï¼‰

    Args:
        token_content: è’²å…¬è‹±token
        platform_user_id: ç”¨æˆ·ID

    Returns:
        list: æ‰€æœ‰é‚€çº¦æ•°æ®åˆ—è¡¨ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        pgy_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
            "cookie": token_content,
            "Content-Type": "application/json"
        }

        all_invites = []  # å­˜å‚¨æ‰€æœ‰é‚€çº¦æ•°æ®
        page_num = 1
        max_pages = 100  # æœ€å¤§åˆ†é¡µæ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯

        while page_num <= max_pages:
            logger.info(f"ğŸ“„ è¯·æ±‚ç¬¬ {page_num} é¡µæ•°æ®...")

            page_data = {
                "pageNum": page_num,
                "pageSize": 20,  # æ”¹ä¸ºæ¯é¡µ20æ¡
                "inviteStatus": "-1",
                "kolIntention": "-1",
                "kolType": 0,
                "searchDateType": 1,
                "showWechat": 0
            }

            # å»¶è¿Ÿè¯·æ±‚ï¼ˆç¬¬ä¸€é¡µåœ¨å¤–éƒ¨å·²å»¶è¿Ÿï¼‰
            if page_num > 1:
                time.sleep(REQUEST_DELAY)

            response = requests.post(
                PGY_API_URL,
                headers=pgy_headers,
                json=page_data,
                verify=False,
                timeout=REQUEST_TIMEOUT
            )

            if response.status_code != 200:
                logger.error(f"è¯·æ±‚ç¬¬ {page_num} é¡µå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                break

            pgy_data = response.json().get('data', {})

            if 'invites' not in pgy_data:
                logger.warning(f"ç¬¬ {page_num} é¡µæ— invitesæ•°æ®")
                break

            current_invites = pgy_data['invites']

            if not current_invites or len(current_invites) == 0:
                logger.info(f"ç¬¬ {page_num} é¡µæ— æ•°æ®ï¼Œåœæ­¢åˆ†é¡µ")
                break

            logger.success(f"âœ… ç¬¬ {page_num} é¡µè·å–åˆ° {len(current_invites)} æ¡æ•°æ®")

            # å–æœ€åä¸€æ¡æ•°æ®çš„inviteId
            last_invite = current_invites[-1]
            last_invite_id = last_invite.get('inviteId')

            if not last_invite_id:
                logger.warning(f"ç¬¬ {page_num} é¡µæœ€åä¸€æ¡æ•°æ®æ— inviteId")
                all_invites.extend(current_invites)
                break

            # æ£€æŸ¥æœ€åä¸€æ¡æ•°æ®æ˜¯å¦å·²å­˜åœ¨
            logger.debug(f"æ£€æŸ¥æœ€åä¸€æ¡æ•°æ® inviteId: {last_invite_id}")

            if check_invite_detail(last_invite_id):
                # å·²å­˜åœ¨ï¼Œè¯´æ˜åˆ°è¾¾å·²æœ‰æ•°æ®ï¼Œåœæ­¢åˆ†é¡µ
                logger.info(f"ğŸ›‘ ç¬¬ {page_num} é¡µå·²åˆ°è¾¾å·²æœ‰æ•°æ®ï¼Œåœæ­¢åˆ†é¡µ")
                all_invites.extend(current_invites)
                break
            else:
                # ä¸å­˜åœ¨ï¼Œç»§ç»­ä¸‹ä¸€é¡µ
                all_invites.extend(current_invites)
                page_num += 1

        if page_num > max_pages:
            logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§åˆ†é¡µæ•° {max_pages}ï¼Œåœæ­¢è¯·æ±‚")

        logger.info(f"ğŸ“Š æ€»å…±è·å– {len(all_invites)} æ¡é‚€çº¦æ•°æ®ï¼ˆ{page_num} é¡µï¼‰")

        return all_invites if all_invites else None

    except Exception as e:
        logger.error(f"è·å–é‚€çº¦æ•°æ®å‡ºé”™: {str(e)}")
        return None


def insert_invites_batch(invites, platform_user_id):
    """æ‰¹é‡æ’å…¥é‚€çº¦æ•°æ®"""
    try:
        headers = {"Content-Type": "application/json"}
        api_url = f"{API_BASE_URL}/api/admin/pgyInvites/pgyInvitesBatchInsert"
        
        insert_data = {
            'invites': invites,
            'pgy_user_id': platform_user_id,
            'check_interval': 'false'
        }
        
        response = requests.post(
            api_url,
            headers=headers,
            json=insert_data,
            timeout=REQUEST_TIMEOUT
        )
        print(response.json())
        
        if response.status_code == 200:
            result = response.json()
            if result.get('code') == 200 or result.get('success'):
                return True
        return False
    except Exception as e:
        logger.error(f"æ’å…¥æ•°æ®å‡ºé”™: {str(e)}")
        return False


def run_spider_task():
    """æ‰§è¡Œçˆ¬è™«ä»»åŠ¡"""
    try:
        start_time = datetime.now()
        logger.info("=" * 60)
        logger.info("ğŸš€ è’²å…¬è‹±é‚€çº¦æ•°æ®åŒæ­¥ç¨‹åºå¯åŠ¨")
        logger.info(f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 60)
        
        # è·å–tokenåˆ—è¡¨
        logger.info("ğŸ“‹ å¼€å§‹è·å–tokenåˆ—è¡¨...")
        tokens = get_token_list()
        
        if not tokens:
            logger.error("âŒ æœªèƒ½è·å–åˆ°tokenåˆ—è¡¨")
            return False
        
        logger.success(f"âœ… æˆåŠŸè·å– {len(tokens)} ä¸ªtoken")
        
        # å¤„ç†æ¯ä¸ªtoken
        skipped_count = 0
        success_count = 0
        fail_count = 0
        
        for idx, token in enumerate(tokens, 1):
            try:
                platform_user_id = token.get('platform_user_id')
                # if platform_user_id != '62b43929000000001b0268e5':
                #     continue
                token_content = token.get('token_content')
                update_time = token.get('update_time')
                
                # éªŒè¯å¿…å¡«å­—æ®µ
                if not platform_user_id or not token_content or not update_time:
                    skipped_count += 1
                    continue
                
                logger.info(f"\n[{idx}/{len(tokens)}] å¤„ç†ç”¨æˆ·: {platform_user_id}")
                
                # æ£€æŸ¥tokenæ—¶é—´
                is_expired, days_diff = check_token_time(update_time)
                if is_expired:
                    skipped_count += 1
                    continue
                
                # è·å–é‚€çº¦æ•°æ®
                logger.info(f"ğŸ“¥ è·å–é‚€çº¦æ•°æ®(ç­‰å¾…{REQUEST_DELAY}ç§’)...")
                time.sleep(REQUEST_DELAY)  # ç¬¬ä¸€é¡µå»¶è¿Ÿ
                invites = get_invites_data(token_content, platform_user_id)
                
                if invites is None:
                    logger.error("âŒ è·å–é‚€çº¦æ•°æ®å¤±è´¥")
                    fail_count += 1
                    continue
                
                if len(invites) == 0:
                    logger.warning("âš ï¸ è¯¥ç”¨æˆ·æ²¡æœ‰é‚€çº¦æ•°æ®")
                    continue
                
                logger.success(f"âœ… è·å–åˆ° {len(invites)} æ¡é‚€çº¦æ•°æ®")
                
                # æ‰¹é‡æ’å…¥æ•°æ®
                logger.info("ğŸ’¾ å¼€å§‹æ’å…¥æ•°æ®...")
                if insert_invites_batch(invites, platform_user_id):
                    logger.success(f"âœ… æ’å…¥æˆåŠŸ (å…±{len(invites)}æ¡)")
                    success_count += 1
                else:
                    logger.error("âŒ æ’å…¥å¤±è´¥")
                    fail_count += 1
                    
            except Exception as e:
                logger.error(f"âŒ å¤„ç†tokenæ—¶å‡ºé”™: {str(e)}")
                fail_count += 1
                continue
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆ")
        logger.info("ğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        logger.info(f"   â±ï¸  æ‰§è¡Œæ—¶é•¿: {duration:.2f} ç§’")
        logger.info(f"   ğŸ“ æ€»tokenæ•°: {len(tokens)}")
        logger.info(f"   âœ… æˆåŠŸå¤„ç†: {success_count}")
        logger.info(f"   âŒ å¤„ç†å¤±è´¥: {fail_count}")
        logger.info(f"   â­ï¸  è·³è¿‡è®°å½•: {skipped_count}")
        logger.info(f"   ğŸ ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è®¾ç½®æ—¥å¿—
        setup_logger()
        
        # åŠ è½½é…ç½®
        scheduler_config = load_config()
        
        logger.info("=" * 60)
        logger.info("ğŸš€ è’²å…¬è‹±é‚€çº¦æ•°æ®åŒæ­¥ç¨‹åº")
        logger.info(f"ğŸ“… å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 60)
        
        # å•æ¬¡è¿è¡Œæ¨¡å¼
        if scheduler_config['run_once']:
            logger.info("âš¡ å•æ¬¡è¿è¡Œæ¨¡å¼")
            success = run_spider_task()
            return success
        
        # è°ƒåº¦å™¨æ¨¡å¼
        elif scheduler_config['enable_scheduler']:
            logger.info("ğŸ”„ è°ƒåº¦å™¨æ¨¡å¼")
            logger.info(f"â° æ‰§è¡Œæ—¶é—´: æ¯å¤© {scheduler_config['daily_time']}")
            logger.info(f"ğŸ” æ£€æŸ¥é—´éš”: {scheduler_config['check_interval']}ç§’")
            logger.info("=" * 60)
            
            # è®¾ç½®å®šæ—¶ä»»åŠ¡
            schedule.every().day.at(scheduler_config['daily_time']).do(run_spider_task)
            logger.info(f"âœ… å·²è®¾ç½®å®šæ—¶ä»»åŠ¡: æ¯å¤© {scheduler_config['daily_time']}")
            logger.info("\nğŸ”„ è°ƒåº¦å™¨è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢...\n")
            
            # è¿è¡Œè°ƒåº¦å™¨
            while True:
                schedule.run_pending()
                time.sleep(scheduler_config['check_interval'])
        
        # è°ƒåº¦å™¨æœªå¯ç”¨
        else:
            logger.info("âš¡ è°ƒåº¦å™¨æœªå¯ç”¨ï¼Œæ‰§è¡Œå•æ¬¡ä»»åŠ¡")
            success = run_spider_task()
            return success
            
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­ç¨‹åº")
        return True
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        return False


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.critical(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {str(e)}")
        sys.exit(1)
